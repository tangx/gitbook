<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>k8sailor: 自己写一个 Kubernetes 控制台</title><link>https://tangx.in/books/k8sailor/</link><description>Recent content on k8sailor: 自己写一个 Kubernetes 控制台</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://tangx.in/books/k8sailor/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://tangx.in/books/k8sailor/chapter01/01-install-k3s-cluster/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter01/01-install-k3s-cluster/</guid><description>搭建 k3s 集群 安装 k3s 安装过程参考
https://tangx.in/2021/06/07/k3s-architecture-single-server/
k3s 集群版本为 v1.21.4。 因此 k8s client-go sdk 的版本也需要安装对应版本
# curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh - [INFO] Finding release for channel stable [INFO] Using v1.21.4+k3s1 as release [INFO] Downloading hash http://rancher-mirror.cnrancher.com/k3s/v1.21.4-k3s1/sha256sum-amd64.txt [INFO] Downloading binary http://rancher-mirror.cnrancher.com/k3s/v1.21.4-k3s1/k3s [INFO] Verifying binary download [INFO] Installing k3s to /usr/local/bin/k3s ... 省略 初始化环境 通过命令创建一些工作负载， 以便后续 k8s api 调用查看</description></item><item><title/><link>https://tangx.in/books/k8sailor/chapter01/02-design-cobra-command/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter01/02-design-cobra-command/</guid><description>使用 cobra 管理命令与参数 tag: https://github.com/tangx/k8sailor/tree/feat/01-cobra-command
为了更加方便的管理配置文件的来源， 这里使用 cobra 进行命令行构建
效果如下
cd cmd/k8sailor &amp;amp;&amp;amp; go run . k8s 管理平台 Usage: k8sailor [flags] Flags: --config string k8s 配置授权文件 (default &amp;#34;./k8sconfig/config.yml&amp;#34;) -h, --help help for k8sailor 编码 变量管理 在 cmd/k8sailor/global 目录中管理 全局 变量。
其中，定义一个 CmdFlag 结构体管理所有 cobra flags。
type CmdFlags struct { Config string `flag:&amp;#34;config&amp;#34; usage:&amp;#34;k8s 配置授权文件&amp;#34; persistent:&amp;#34;true&amp;#34;` } var Flags = &amp;amp;CmdFlags{ Config: &amp;#34;.</description></item><item><title/><link>https://tangx.in/books/k8sailor/chapter01/03-connect-cluster/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter01/03-connect-cluster/</guid><description>连接 k3s 集群 tag: https://github.com/tangx/k8sailor/tree/feat/02-connect-cluster
使用 sdk 链接 k3s cluster 并获取 deployment 信息
cd cmd/k8sailor &amp;amp;&amp;amp; go run . * my-nginx-1 (1 replicas) * my-nginx-2 (2 replicas) 下载 client-go sdk 之前在安装 k3s 集群的时候，版本是 v0.21.4。 因此。 这里选择 client-go sdk 的版本也是 v0.21.4
如果还有其他环境， 可以使用 go mod edit 命令锁定 client-go 的版本
go get k8s.io/client-go@v0.21.4 go mod edit -replace=k8s.io/client-go=k8s.io/client-go@v0.21.4 连接集群并获取 deployment https://github.</description></item><item><title/><link>https://tangx.in/books/k8sailor/chapter01/04-init-httpserver/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter01/04-init-httpserver/</guid><description>使用 gin 初始化一个 API Server tag: https://github.com/tangx/k8sailor/tree/feat/04-httpserver-initial
cd cmd/k8sailor &amp;amp;&amp;amp; go run . httpserver 启动 web 服务器 Usage: k8sailor httpserver [flags] Flags: -h, --help help for httpserver Global Flags: --config string k8s 配置授权文件 (default &amp;#34;./k8sconfig/config.yml&amp;#34;) 2021/09/24 07:56:51 open config/local.yml: no such file or directory [GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached. [GIN-debug] [WARNING] Running in &amp;#34;debug&amp;#34; mode. Switch to &amp;#34;release&amp;#34; mode in production.</description></item><item><title/><link>https://tangx.in/books/k8sailor/chapter01/05-design-restful-api-and-response-data/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter01/05-design-restful-api-and-response-data/</guid><description>RESTful-API 与 http-response-data tag: https://github.com/tangx/k8sailor/tree/feat/05-design-restful-api-and-response-data
强烈建议使用 RESTful 风格来设计 API 文档。
RESTful api # kubectl create deployment nginx-tools --image nginx:alpine --output=yaml --dry-run=clientapiVersion:apps/v1kind:Deploymentmetadata:creationTimestamp:nulllabels:app:nginx-toolsname:nginx-tools# ... 省略# kubectl create namespace hello --dry-run=client -o yamlapiVersion:v1kind:Namespacemetadata:creationTimestamp:nullname:hello# ... 省略可以看到， k8s api 中都有一个对应的 kind 描述资源类型， 这个正好符合 RESTful 中资源定位的需求。
大概就是这样。
# 所有资源操作 GET /appname/v0/:resources ## 特定志愿操作 GET /appname/v0/:resources/:name?params POST /appname/v0/:resources/:name?params DELETE /appname/v0/:resources/:name # 获取所有 deployemnt 信息, 默认会设计一些限定条件， 比如说 namespace=default GET /k8sailor/v0/deployments # 针对特定名称资源的 deployment 操作 GET /k8sailor/v0/deployments/my-nginx-01?</description></item><item><title/><link>https://tangx.in/books/k8sailor/chapter02/06-get-all-deployments/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter02/06-get-all-deployments/</guid><description>使用 api/biz/dao 分层结构管理数据请求，获取 deployment 数据 tag: https://github.com/tangx/k8sailor/tree/feat/06-get-all-deployments
client -&amp;gt; apis -&amp;gt; biz -&amp;gt; dao -&amp;gt; 将业务逻辑部分分为经典三层，想法是这样的，可能实现有错误。
apis 接入层: 只用于管理 http 请求与交互。 biz 业务层: 用于处理 api 层来的请求， 封装原始数据 dao 数据访问层: 与数据库, cluster 等交互。 存取数据。 重新调整目录结构 新创建 /internal 目录用于存放业务信息 在 /internal 目录下新创建 业务层 /internal/biz 和 k8s dao 层 /internal/k8sdao 将 apis 接入层 从原来的 /cmd/k8sailor/apis 移动到了 /internal/apis 使用 jarvis, 删除 cobra flags 统一使用 jarvis 进行变量管理， 因此删除了 global/config.</description></item><item><title/><link>https://tangx.in/books/k8sailor/chapter02/07-initial-vue3-vite2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter02/07-initial-vue3-vite2/</guid><description>初始化 vue3+vite 安装 # 初始化项目 yarn create vite webapp --template vue-ts cd webapp ## 安装依赖 yarn ## 启动查看 vue3 是否正常 yarn dev ## 安装 less 支持， 以后写样式用 yarn add less 清理环境 删除 /webapp/src/components 下的 HelloWorld.vue。 并新建一个 Deployment.vue。 这里使用 vue3 的 setup 语法糖。 在 &amp;lt;template&amp;gt; 标签对中创建内容 &amp;lt;h3&amp;gt;hello deployments&amp;lt;/h3&amp;gt;
&amp;lt;template&amp;gt; &amp;lt;h3&amp;gt;hello deployments&amp;lt;/h3&amp;gt; &amp;lt;/template&amp;gt; &amp;lt;script setup lang=&amp;#39;ts&amp;#39;&amp;gt; &amp;lt;/script&amp;gt; &amp;lt;style lang=&amp;#39;less&amp;#39; scoped&amp;gt; &amp;lt;/style&amp;gt; 修改 /webapp/src/App.</description></item><item><title/><link>https://tangx.in/books/k8sailor/chapter02/08-fetch-and-display-deployments/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter02/08-fetch-and-display-deployments/</guid><description>获取并展示 Deployments 信息 tag: https://github.com/tangx/k8sailor/tree/feat/08-fetch-and-display-deployments
使用 Axios 请求 Deployments 数据 安装 axios 客户端
# 安装 axios yarn add axios 创建 /webapp/src/apis 目录， 用于存放所有针对 k8sailor 后端的数据请求
使用 axios config 模式初始化一个客户端 /webapp/src/apis/httpc.ts
axios config 模式可以创建一个 http 客户端，其中包含了各种各样的初始化参数， 使用这个模式就不用在每个请求中都写重复的内容了。
import axios from &amp;#39;axios&amp;#39; // 使用 config 模式 // https://github.com/axios/axios#config-defaults let httpc = axios.create({ baseURL:&amp;#34;http://127.0.0.1:8088/k8sailor/v0&amp;#34; }) export default httpc 创建 deployments 的请求参数 /webapp/src/apis/deployment.</description></item><item><title/><link>https://tangx.in/books/k8sailor/chapter02/09-get-pods-by-deployment-label/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter02/09-get-pods-by-deployment-label/</guid><description>通过 deployment label 获取 pod 信息 tag: https://github.com/tangx/k8sailor/tree/feat/09-get-pods-by-deployment-label
有了之前结构铺垫， 获取 Pod 还是很简单简单的。 其中需要注意的是 ListOptions 中的 LabelSelector 是一个字符串， 多组 key=value 之间使用 逗号 , 进行连接。
labelSelector := `key1=value1,key2=value2,...` 而通过 client-go API 获取的 Deployment, Pod 等信息中的 MatchLabel 字段是一个 map[string]string 的 map。
因此， 在使用 k8s client 查询的时候， 需要对进行一些传参转换。
// convertMapToSelector convert map to string, use comma connection: k1=v1,k2=v2 func convertMapToSelector(labels map[string]string) string { l := []string{} for k, v := range labels { l = append(l, fmt.</description></item><item><title/><link>https://tangx.in/books/k8sailor/chapter02/10-vue-router-and-less/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter02/10-vue-router-and-less/</guid><description>使用 vue-router 进行路由管理 tag: https://github.com/tangx/k8sailor/tree/feat/10-vue-router-and-less
使用 vue-router 路由管理 安装 vue-router 支持参考 https://tangx.in/2021/09/28/vue3-vue-router/
将默认的 /webapp/src/App.vue 作为最基本的入口， 除了引入 Index.vue 文件模块，不进行其他操作， 保持整洁。 其行为类似 golang 中的 main.go。
创建 /webapp/src/components/Index.vue 模块作为 index 入口文件， 也是主要的布局页面。
路由信息(router-link) 将放置在页面左侧 路由展示(router-view) 作为占位符放在右侧。 所有数据展示类模块都放在 /webapp/src/components/views 目录下。 所有内容将通过 vue-router 组件渲染， 展示在 Index.vue 模块的 router-view 区域。
使用 less 进行 Index 部署 less https://lesscss.</description></item><item><title/><link>https://tangx.in/books/k8sailor/chapter02/11-display-deployment-detail/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter02/11-display-deployment-detail/</guid><description>展示 deployment 详情页 tag: https://github.com/tangx/k8sailor/tree/feat/11-display-deployment-detail
之前在后端已经将详情页的展示接口拆成了 2个
其一是根据 name 获取 单个 deployment /deployments/:name 其二是根据 deployment name 获取 关联 的 pods 信息 /deployments/:name/pod 页面展示就是两个接口请求与数据展示的简单操作， 和之前 deployment 页面一样， 没什么好说的。
typescript 的 interface 衍生 不过， 在遇到第二个、第三个接口出现的时候， 发现之前对于 deployment list 返回的数据结构设计出现了问题。
当时是将 code, error 两个字段直接内嵌到 Deployment 的接口设计之中。
export interface Deployment { code: number error: string data: DeploymentItem[] } export interface DeploymentItem { images: string[] name: string namespace: string replicas: number status: { availableReplicas: number replicas: number unavailableReplicas: number } } 现在发现， 如果需要在对 单 Deployment 和 多 Pod 进行返回的时候， 再重复这样将 code, error 耦合到响应接口里面就额外的冗余了。</description></item><item><title/><link>https://tangx.in/books/k8sailor/chapter02/12-deployment-scale-and-params-validate/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter02/12-deployment-scale-and-params-validate/</guid><description>deployment 副本数量设置 与 参数的有效性验证 tag: https://github.com/tangx/k8sailor/tree/feat/12-deployment-scale-and-params-validate
deployment scale kubectl scale deployment my-nginx-1 --replicas 1 在 client-go sdk 中， scale 参数是一个对象， 因此不能直接传入 一个数字。
需要通过 GetScale() 方法获取到 *autoscalingv1.Scale 对象。 修改 Scale 对象中的 Replicas 数值。 使用 UpdateScale() 方法更新设置。 SetDeploymentReplicas
params validtor 参数验证在任何情况下都不能放松警惕， 尤其是 边界验证 和 0值混淆 。
对于参数的验证， 可以自己在业务代码中实现， 也可以使用已有的公共库。 gin 默认使用的是 https://github.com/go-playground/validator
// SetDeploymentReplicasInput 调整 deployment pod 数量参数 // Replicas 为了避免 **0值** 影响。 // 1.</description></item><item><title/><link>https://tangx.in/books/k8sailor/chapter02/13-k8s-informer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter02/13-k8s-informer/</guid><description>k8s informer tag: https://github.com/tangx/k8sailor/tree/feat/13-k8s-informer
从应用层面来说， 创建 informer 并启动之后就与 k8s cluster 创建了一个长链接并订阅了 某个资源 Resource 的变化。
至于订阅后得到的数据要怎么用完全取决于订阅者的业务设计。
Shared Informer Factory 共享机制 Informer 又称为 Shared Informer，表明是可以共享使用的，在使用 client-go 写代码时，若同一资源的 Informer 被实例化太多次，每个 Informer 使用一个 Reflector，会运行过多的相同 ListAndWatch（即图中的第一步），太多重复的序列化和反序列化会导致 k8s API Server 负载过重。
而 Shared Informer 通过对同一类资源 Informer 共享一个 Reflector 可以节约很多资源，这通过 map 数据结构即可实现这样一个共享 Informer 机制。
// Start initializes all requested informers. func (f *sharedInformerFactory) Start(stopCh &amp;lt;-chan struct{}) { f.</description></item><item><title/><link>https://tangx.in/books/k8sailor/chapter02/14-some-optimize/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter02/14-some-optimize/</guid><description>一些优化 tag: https://github.com/tangx/k8sailor/tree/feat/14-some-optimize
将 LabelSelector 转换为 Selector client-go 提供了一个方法， 可以将 Resource 中的 LabelSelector 转换为 Selector, 并且 Selector 结构提供了一些常用的方法。 如 String
import ( metav1 &amp;#34;k8s.io/apimachinery/pkg/apis/meta/v1&amp;#34; ) func() { selector, _ := metav1.LabelSelectorAsSelector(dep.Spec.Selector) x := selector.String() fmt.Println(x) }() 因此在使用 GetXXXByLabels 时， api 层 可以考虑 接收 map[string]string 类型的参数。 而在 biz 层应该将 不同类型 的参数 统一 转换为格式为 key1=value1,key2=value2 的 string 类型参数。 在 dao 层只接收 string 类型的 string。 这样就实现了前后一致性的问题。</description></item><item><title/><link>https://tangx.in/books/k8sailor/chapter02/15-delete-deployment-and-pod-by-name/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter02/15-delete-deployment-and-pod-by-name/</guid><description>根据名字删除 deployment 和 pod tag: https://github.com/tangx/k8sailor/tree/feat/15-delete-deployment-and-pod-by-name
调用 k8s api 没什么好说的。
k8sdao
func DeleteDeploymentByName(ctx context.Context, namespace string, name string) error { opts := metav1.DeleteOptions{} return clientset.AppsV1().Deployments(namespace).Delete(ctx, name, opts) } biz
type DeleteDeploymentByNameInput struct { Name string `uri:&amp;#34;name&amp;#34;` Namespace string `query:&amp;#34;namespace&amp;#34;` } // DeleteDeploymentByName 根据名字删除 deployment func DeleteDeploymentByName(ctx context.Context, input DeleteDeploymentByNameInput) error { err := k8sdao.DeleteDeploymentByName(ctx, input.Namespace, input.Name) if err != nil { return fmt.Errorf(&amp;#34;k8s internal error: %w&amp;#34;, err) } return nil } api</description></item><item><title/><link>https://tangx.in/books/k8sailor/chapter02/16-create-deployment/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter02/16-create-deployment/</guid><description>创建 deployment tag: https://github.com/tangx/k8sailor/tree/feat/16-create-deployment
使用 kubectl 命令创建如下
kubectl create deployment my-nginx-5 --image=nginx:alpine --replicas=3 --port=80 创建成功后查看结果， 大部分参数为默认参数。
# kgd -o yaml my-nginx-5apiVersion:apps/v1kind:Deploymentmetadata:labels:app:my-nginx-5# 根据 deployment 自动匹配名字自动生成name:my-nginx-5 # 用户指定namespace:default# 用户选择，默认为当前 namespacespec:progressDeadlineSeconds:600# 默认值replicas:3# --replicasselector:matchLabels:app:my-nginx-5template:metadata:labels:app:my-nginx-5spec:containers:- image:nginx:alpine # --imageimagePullPolicy:IfNotPresentname:nginx# 根据镜像名字获取ports:# --port- containerPort:80protocol:TCP# ... 省略 ... 在使用命令行传递参数的时候只传递了 name, image, replicas, pods
kubectl 根据传递的信息， 自动补全了一些信息
以 name 补全了 labels： app: my-nginx-5 以 image 生成了 container name； 如果传递多个 相同名称 image 将会报错 container name 冲突。 接下来的工作就真没什么技术含量了， 就是最简单最无脑的拼凑字段。</description></item><item><title/><link>https://tangx.in/books/k8sailor/chapter02/17-pod-phase-and-status/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter02/17-pod-phase-and-status/</guid><description>Pod 的阶段(phase)与状态(status) Pod 的生命周期 https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/
Pod 的 Status 不是 Phase。
Pod 的 Status 需要根据 Pod 中的 ContainerStatuses 进行计算得到。
Phase 阶段 描述 Pending（悬决） Pod 已被 Kubernetes 系统接受，但有一个或者多个容器尚未创建亦未运行。此阶段包括等待 Pod 被调度的时间和通过网络下载镜像的时间， Running（运行中） Pod 已经绑定到了某个节点，Pod 中所有的容器都已被创建。至少有一个容器仍在运行，或者正处于启动或重启状态。 Succeeded（成功） Pod 中的所有容器都已成功终止，并且不会再重启。 Failed（失败） Pod 中的所有容器都已终止，并且至少有一个容器是因为失败终止。也就是说，容器以非 0 状态退出或者被系统终止。 Unknown（未知） 因为某些原因无法取得 Pod 的状态。这种情况通常是因为与 Pod 所在主机通信失败。 其中 Running 阶段包含了很多行为， 如 1.</description></item><item><title/><link>https://tangx.in/books/k8sailor/chapter02/18-vue3-create-deployment/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter02/18-vue3-create-deployment/</guid><description>创建 deployment</description></item><item><title/><link>https://tangx.in/books/k8sailor/chapter02/19-create-service/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter02/19-create-service/</guid><description>为 Deployment 创建 Service tag: https://github.com/tangx/k8sailor/tree/feat/19-create-service
https://kubernetes.io/zh/docs/concepts/services-networking/service/#externalname
kubectl create service clusterip nginx-web --clusterip=&amp;#34;port:targetPort&amp;#34; kubectl create service clusterip nginx-web --clusterip=&amp;#34;8082:80&amp;#34; kubectl create service nodeport nginx-web --clusterip=&amp;#34;8081:80&amp;#34; 需要注意, 使用 kubectl get service 查看到的 Ports 的展示结果为 port:nodePort， 而 targetPort 不展示。
# kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE demo-nginx-nodeport-3 NodePort 10.43.181.29 &amp;lt;none&amp;gt; 80:32425/TCP 4s port, targetPort, nodePort 端口映射中的四个 比较关键 的要素:</description></item><item><title/><link>https://tangx.in/books/k8sailor/chapter02/20-create-ingress/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tangx.in/books/k8sailor/chapter02/20-create-ingress/</guid><description>创建 ingress tag: https://github.com/tangx/k8sailor/tree/feat/20-create-ingress
k8s ingress https://kubernetes.io/zh/docs/concepts/services-networking/ingress/
# Create an ingress with a default backend kubectl create ingress ingdefault --class=default \ --default-backend=defaultsvc:http \ --rule=&amp;#34;foo.com/*=svc:8080,tls=secret1&amp;#34; --dry-run -o yaml apiVersion:networking.k8s.io/v1kind:Ingressmetadata:creationTimestamp:nullname:ingdefaultspec:defaultBackend:service:name:defaultsvcport:name:httpingressClassName:defaultrules:- host:foo.comhttp:paths:- backend:service:name:svcport:number:8080path:/pathType:Prefix # 匹配方式tls:- hosts:- foo.comsecretName:secret1status:loadBalancer:{}路径类型 Ingress 中的每个路径都需要有对应的路径类型（Path Type）。未明确设置 pathType 的路径无法通过合法性检查。当前支持的路径类型有三种：
ImplementationSpecific ：对于这种路径类型，匹配方法取决于 IngressClass。 具体实现可以将其作为单独的 pathType 处理或者与 Prefix 或 Exact 类型作相同处理。
Exact ：精确匹配 URL 路径，且区分大小写。</description></item></channel></rss>