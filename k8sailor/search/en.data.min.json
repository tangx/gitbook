[{"id":0,"href":"/books/k8sailor/","title":"","parent":"","content":"k8sailor     k8s manage dashbooard\ngolang 练习的前后端\n Summary     环境准备      搭建 k3s 集群 使用 cobra 管理命令与参数 连接 k3s 集群并获取 deployments 信息 使用 gin 初始化一个 API server 设计 RESTful API 和响应请求  数据获取     使用 api/biz/dao 分层结构管理数据请求，获取 deployment 数据 vue3 - 初始化 vue3 + vite2 vue3 - 获取并展示 deployments 信息 通过 deployment label 获取 pod 信息 vue3 - 使用 vue-router 和 less 优化展示页面 vue3 - 展示 deployment 详情页 deployment 副本数量设置 与 参数的有效性验证 使用 informer 监听变化并在本地缓存数据 一些优化  将 LabelSelector 转换为 Selector 自动刷新前端数据 使用 informer 订阅 k8s event defineProps 传入自定义类型   根据名字删除 deployment 和 pod 创建 deployment Pod 的阶段与状态 vue3 - 创建 deployment 页面 创建 deployment service 创建 ingress  feed      ","description":"k8sailor     k8s manage dashbooard\ngolang 练习的前后端\n Summary     环境准备      搭建 k3s 集群 使用 cobra 管理命令与参数 连接 k3s 集群并获取 deployments 信息 使用 gin 初始化一个 API server 设计 RESTful API 和响应请求  数据获取     使用 api/biz/dao 分层结构管理数据请求，获取 deployment 数据 vue3 - 初始化 vue3 + vite2 vue3 - 获取并展示 deployments 信息 通过 deployment label 获取 pod 信息 vue3 - 使用 vue-router 和 less 优化展示页面 vue3 - 展示 deployment 详情页 deployment 副本数量设置 与 参数的有效性验证 使用 informer 监听变化并在本地缓存数据 一些优化  将 LabelSelector 转换为 Selector 自动刷新前端数据 使用 informer 订阅 k8s event defineProps 传入自定义类型   根据名字删除 deployment 和 pod 创建 deployment Pod 的阶段与状态 vue3 - 创建 deployment 页面 创建 deployment service 创建 ingress  feed      "},{"id":1,"href":"/books/k8sailor/chapter01/01-install-k3s-cluster/","title":"01 Install K3s Cluster","parent":"Chapter01","content":"搭建 k3s 集群     安装     k3s 安装过程参考\n https://tangx.in/2021/06/07/k3s-architecture-single-server/\n k3s 集群版本为 v1.21.4。 因此 k8s client-go sdk 的版本也需要安装对应版本\n# curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh - [INFO] Finding release for channel stable [INFO] Using v1.21.4+k3s1 as release [INFO] Downloading hash http://rancher-mirror.cnrancher.com/k3s/v1.21.4-k3s1/sha256sum-amd64.txt [INFO] Downloading binary http://rancher-mirror.cnrancher.com/k3s/v1.21.4-k3s1/k3s [INFO] Verifying binary download [INFO] Installing k3s to /usr/local/bin/k3s ... 省略 初始化环境     通过命令创建一些工作负载， 以便后续 k8s api 调用查看\n这里创建了两个 deployment:\n my-nginx-1 : 1 个 pod my-nginx-2 : 2 个 pod  # kubectl create deployment my-nginx-1 --image=nginx:alpine deployment.apps/my-nginx-1 created # kubectl create deployment my-nginx-2 --image=nginx:alpine --replicas=2 deployment.apps/my-nginx-2 created 通过 kubectl 命令查看结果\n# kubectl get pod NAME READY STATUS RESTARTS AGE my-nginx-1-6d9577949b-98hzv 1/1 Running 0 105s my-nginx-2-cd544c6f7-sf68x 1/1 Running 0 91s my-nginx-2-cd544c6f7-zm974 1/1 Running 0 91s 复制 k3s config 文件     之后将使用 config 文件的访问链接访问 k3s 集群。\n下载 config /etc/rancher/k3s/k3s.yaml 文件到本地， 并修改链接地址。\napiVersion:v1clusters:- cluster:certificate-authority-data:XXXXXXyyyyzzzzzserver:https://your-k3s-host:6443name:default# ... 省略目录结构     # tree . ├── README.md ├── cmd │ └── k8sailor │ ├── k8sconfig │ │ └── config.yml │ └── main.go ","description":"搭建 k3s 集群     安装     k3s 安装过程参考\n https://tangx.in/2021/06/07/k3s-architecture-single-server/\n k3s 集群版本为 v1.21.4。 因此 k8s client-go sdk 的版本也需要安装对应版本\n# curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh - [INFO] Finding release for channel stable [INFO] Using v1.21.4+k3s1 as release [INFO] Downloading hash http://rancher-mirror.cnrancher.com/k3s/v1.21.4-k3s1/sha256sum-amd64.txt [INFO] Downloading binary http://rancher-mirror.cnrancher.com/k3s/v1.21.4-k3s1/k3s [INFO] Verifying binary download [INFO] Installing k3s to /usr/local/bin/k3s ... 省略 初始化环境     通过命令创建一些工作负载， 以便后续 k8s api 调用查看"},{"id":2,"href":"/books/k8sailor/chapter01/02-design-cobra-command/","title":"02 Design Cobra Command","parent":"Chapter01","content":"使用 cobra 管理命令与参数      tag: https://github.com/tangx/k8sailor/tree/feat/01-cobra-command\n 为了更加方便的管理配置文件的来源， 这里使用 cobra 进行命令行构建\n效果如下\ncd cmd/k8sailor \u0026amp;\u0026amp; go run . k8s 管理平台 Usage: k8sailor [flags] Flags: --config string k8s 配置授权文件 (default \u0026#34;./k8sconfig/config.yml\u0026#34;) -h, --help help for k8sailor 编码     变量管理     在 cmd/k8sailor/global 目录中管理 全局 变量。\n其中，定义一个 CmdFlag 结构体管理所有 cobra flags。\ntype CmdFlags struct { Config string `flag:\u0026#34;config\u0026#34; usage:\u0026#34;k8s 配置授权文件\u0026#34; persistent:\u0026#34;true\u0026#34;` } var Flags = \u0026amp;CmdFlags{ Config: \u0026#34;./k8sconfig/config.yml\u0026#34;, } cobra     在 cmd/k8sailor/cmd 中管理所有 cobra 命令。 root.go\n在代码中使用了 cobrautils 库帮助管理 flag 绑定。\nfunc init() { cobrautils.BindFlags(rootCmd, global.Flags) } 启动     在 main.go 调用 cmd/root.go 的启动函数。 运行结果如上所示。\n目录结构     # tree  . ├── README.md ├── cmd │ └── k8sailor │ ├── cmd │ │ └── root.go │ ├── global │ │ └── config.go │ ├── k8sconfig │ │ └── config.yml │ └── main.go ├── go.mod └── go.sum 6 directories, 9 files ","description":"使用 cobra 管理命令与参数      tag: https://github.com/tangx/k8sailor/tree/feat/01-cobra-command\n 为了更加方便的管理配置文件的来源， 这里使用 cobra 进行命令行构建\n效果如下\ncd cmd/k8sailor \u0026amp;\u0026amp; go run . k8s 管理平台 Usage: k8sailor [flags] Flags: --config string k8s 配置授权文件 (default \u0026#34;./k8sconfig/config.yml\u0026#34;) -h, --help help for k8sailor 编码     变量管理     在 cmd/k8sailor/global 目录中管理 全局 变量。\n其中，定义一个 CmdFlag 结构体管理所有 cobra flags。\ntype CmdFlags struct { Config string `flag:\u0026#34;config\u0026#34; usage:\u0026#34;k8s 配置授权文件\u0026#34; persistent:\u0026#34;true\u0026#34;` } var Flags = \u0026amp;CmdFlags{ Config: \u0026#34;."},{"id":3,"href":"/books/k8sailor/chapter01/03-connect-cluster/","title":"03 Connect Cluster","parent":"Chapter01","content":"连接 k3s 集群      tag: https://github.com/tangx/k8sailor/tree/feat/02-connect-cluster\n 使用 sdk 链接 k3s cluster 并获取 deployment 信息\ncd cmd/k8sailor \u0026amp;\u0026amp; go run . * my-nginx-1 (1 replicas) * my-nginx-2 (2 replicas) 下载 client-go sdk     之前在安装 k3s 集群的时候，版本是 v0.21.4。 因此。 这里选择 client-go sdk 的版本也是 v0.21.4\n如果还有其他环境， 可以使用 go mod edit 命令锁定 client-go 的版本\ngo get k8s.io/client-go@v0.21.4 go mod edit -replace=k8s.io/client-go=k8s.io/client-go@v0.21.4 连接集群并获取 deployment      https://github.com/kubernetes/client-go/blob/master/examples/create-update-delete-deployment/main.go\n 连接到 cluster 的鉴权方式有多种， 后面可以根据 cobra 传递的参数值， 选择不同的鉴权方式。 这里直接参考官方 demo 使用配置文件方式鉴权。\n修改一下 kubeconfig 配置来源地址。\npkg/k8s/cluster.go\n// 从 cobra 配置中获取地址 kubeconfig := \u0026amp;global.Flags.Config // 其他一样 config, err := clientcmd.BuildConfigFromFlags(\u0026#34;\u0026#34;, *kubeconfig) if err != nil { panic(err) } clientset, err := kubernetes.NewForConfig(config) if err != nil { panic(err) } /* clientset 测试开始， 打印 default namespace 下的所有 deployment */ depClient := clientset.AppsV1().Deployments(apiv1.NamespaceDefault) list, err := depClient.List(context.TODO(), metav1.ListOptions{}) if err != nil { panic(err) } for _, d := range list.Items { fmt.Printf(\u0026#34; * %s (%d replicas)\\n\u0026#34;, d.Name, *d.Spec.Replicas) } /* clienset 测试结束 */ 运行     在 cmd/root.go 中调用 k8s cluster 的连接函数\nvar rootCmd = \u0026amp;cobra.Command{ // .. 省略 \tRun: func(cmd *cobra.Command, args []string) { // 连接 k3s \tk8s.Connent() }, } 运行结果如开篇所示。\n","description":"连接 k3s 集群      tag: https://github.com/tangx/k8sailor/tree/feat/02-connect-cluster\n 使用 sdk 链接 k3s cluster 并获取 deployment 信息\ncd cmd/k8sailor \u0026amp;\u0026amp; go run . * my-nginx-1 (1 replicas) * my-nginx-2 (2 replicas) 下载 client-go sdk     之前在安装 k3s 集群的时候，版本是 v0.21.4。 因此。 这里选择 client-go sdk 的版本也是 v0.21.4\n如果还有其他环境， 可以使用 go mod edit 命令锁定 client-go 的版本\ngo get k8s.io/client-go@v0.21.4 go mod edit -replace=k8s.io/client-go=k8s.io/client-go@v0.21.4 连接集群并获取 deployment      https://github."},{"id":4,"href":"/books/k8sailor/chapter01/04-init-httpserver/","title":"04 Init Httpserver","parent":"Chapter01","content":"使用 gin 初始化一个 API Server      tag: https://github.com/tangx/k8sailor/tree/feat/04-httpserver-initial\n cd cmd/k8sailor \u0026amp;\u0026amp; go run . httpserver 启动 web 服务器 Usage: k8sailor httpserver [flags] Flags: -h, --help help for httpserver Global Flags: --config string k8s 配置授权文件 (default \u0026#34;./k8sconfig/config.yml\u0026#34;) 2021/09/24 07:56:51 open config/local.yml: no such file or directory [GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached. [GIN-debug] [WARNING] Running in \u0026#34;debug\u0026#34; mode. Switch to \u0026#34;release\u0026#34; mode in production. - using env: export GIN_MODE=release - using code: gin.SetMode(gin.ReleaseMode) [GIN-debug] GET /k8sailor/v0/ping --\u0026gt; github.com/tangx/k8sailor/cmd/k8sailor/apis.RootGroup.func1 (3 handlers) [GIN-debug] Listening and serving HTTP on :8088 创建 pkg/confgin 初始化配置文件     为了方便服务配置管理， 将使用 [使用 jarvis 初始化配置](#使用 jarvis 初始化配置)\n需要对 httpserver pkg/confgin/gin.go 进行一些初始化配置\n// Server 定义一个 gin httpserver 的关键字段 // `env:\u0026#34;\u0026#34;` 可以通过 `github.com/go-jarvis/jarvis` 库渲染成配置文件 type Server struct { Host string `env:\u0026#34;\u0026#34;` Port int `env:\u0026#34;\u0026#34;` Appname string `env:\u0026#34;\u0026#34;` engine *gin.Engine } 其中需要额外强调的是, httpserver 必须 有自己的 应用名 的前缀路由。 应该 有自己的版本路由。\nhttp://127.0.0.1:8088/appname/v0/ping 在服务容器化后， 具有自己 应用名 路由的服务对 各家 ingress 规则都是友好的。 如果没有， 上线之后要强行使用 rewrite 实现的话， 那就必须依赖 ingress controller 的实现了。\n 如果 rewrite 规则里面 正则表达式 ， 那就让运维哭去吧\n 目前所知\n nginx ingress controller 支持 rewrite， 支持正则表达式 traefik 好像可以使用 middleware 实现， 不支持正则表达式 istio 有自己的规则， 但不支持正则表达式  // RegisterRoute 注册 func (s *Server) RegisterRoute(registerFunc func(rg *gin.RouterGroup)) { // 注册以服务名为根的路由信息，方便在 k8s ingress 中做转发 \tbase := s.engine.Group(s.Appname) // 注册业务子路由 \tregisterFunc(base) } 使用 jarvis 初始化配置     jarvis 是一个对 配置解析 和 配置加载 操作封装的库。\n 可以方便的通过 config struct 解析出对应的配置参数。 在启动时， 支持通过 配置文件 和 环境变量 加载配置参数， 对 k8s 容器应用还算友好。 支持 giltab 分支配置特点， 可以在不同分支使用不同的变量值。  具体使用案例， 可以参考 github 的 demo github.com/go-jarvis/jarvis\n// 定义服务相关信息 var ( HttpServer = \u0026amp;confgin.Server{} app = jarvis.App{ Name: \u0026#34;k8sailor\u0026#34;, } ) // 使用 jarvis 初始化配置文件 func init() { config := \u0026amp;struct { HttpServer *confgin.Server }{ HttpServer: HttpServer, } app.Conf(config) } 在运行的时候， 会在 运行 根目录生成 config/default.yml 文件。 该文件不要直接修改， 每次运行将被覆盖。\n加载顺序 default.yml -\u0026gt; config.yml -\u0026gt; local.yml / config.branch.yml -\u0026gt; env。\n如果本地开发， 可以把一些关键的敏感配置放在 local.yml 中并 .gitignore 忽略。\n为命令行添加 httpserver 子命令     初始化 cmd/httpserver.go 子命令\n并设置启动命令\n// runHttpserver 启动 http server func runHttpserver() { // 1. 将 apis 注册到 httpserver 中 \tglobal.HttpServer.RegisterRoute(apis.RootGroup) // 2. 启动服务 \tif err := global.HttpServer.Run(); err != nil { logrus.Fatalf(\u0026#34;start httpserver failed: %v\u0026#34;, err) } } 完成之后， 在 cmd/root.go 命令中添加子命令\nfunc init() { cobrautils.BindFlags(rootCmd, global.Flags) // 添加子命令 \trootCmd.AddCommand(cmdHttpserver) } 创建并注册路由     自定义启动参数     由于是用了 jarvis 库， 在程序启动的时候， 会在运行目录生成 config/defualt.yml 配置文件。\n复制并重命名为 config.yml 覆盖默认值。\nk8sailor__HttpServer_Appname:k8sailork8sailor__HttpServer_Host:\u0026#34;\u0026#34;k8sailor__HttpServer_Port:8088启动     如开头所示， 可以看到, 配置项已成功被应用\n httpserver 的根路由为 /k8sailor/v0/xxxxx httpserver 的监听端口为 8088  如果要在容器中运行， 只需要在容器中注入相同变量名的变量\nexport k8sailor__HttpServer_Appname=k8sailor ","description":"使用 gin 初始化一个 API Server      tag: https://github.com/tangx/k8sailor/tree/feat/04-httpserver-initial\n cd cmd/k8sailor \u0026amp;\u0026amp; go run . httpserver 启动 web 服务器 Usage: k8sailor httpserver [flags] Flags: -h, --help help for httpserver Global Flags: --config string k8s 配置授权文件 (default \u0026#34;./k8sconfig/config.yml\u0026#34;) 2021/09/24 07:56:51 open config/local.yml: no such file or directory [GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached. [GIN-debug] [WARNING] Running in \u0026#34;debug\u0026#34; mode. Switch to \u0026#34;release\u0026#34; mode in production."},{"id":5,"href":"/books/k8sailor/chapter01/05-design-restful-api-and-response-data/","title":"05 Design Restful API and Response Data","parent":"Chapter01","content":"RESTful-API 与 http-response-data      tag: https://github.com/tangx/k8sailor/tree/feat/05-design-restful-api-and-response-data\n 强烈建议使用 RESTful 风格来设计 API 文档。\nRESTful api     # kubectl create deployment nginx-tools --image nginx:alpine --output=yaml --dry-run=clientapiVersion:apps/v1kind:Deploymentmetadata:creationTimestamp:nulllabels:app:nginx-toolsname:nginx-tools# ... 省略# kubectl create namespace hello --dry-run=client -o yamlapiVersion:v1kind:Namespacemetadata:creationTimestamp:nullname:hello# ... 省略可以看到， k8s api 中都有一个对应的 kind 描述资源类型， 这个正好符合 RESTful 中资源定位的需求。\n大概就是这样。\n# 所有资源操作 GET /appname/v0/:resources ## 特定志愿操作 GET /appname/v0/:resources/:name?params POST /appname/v0/:resources/:name?params DELETE /appname/v0/:resources/:name # 获取所有 deployemnt 信息, 默认会设计一些限定条件， 比如说 namespace=default GET /k8sailor/v0/deployments # 针对特定名称资源的 deployment 操作 GET /k8sailor/v0/deployments/my-nginx-01?namespace=kube-system DELETE /k8sailor/v0/deployments/my-nginx-01?namespace=default 回到代码中 /cmd/k8sailor/apis/route.go\n// RootGroup 向 httpserver 注册根路由 func RootGroup(base *gin.RouterGroup) { // ... 省略  // 创建 deployment 路由组 \tdeployment := v0.Group(\u0026#34;/deployments\u0026#34;) { // 针对 所有 deployment 操作， 这里还没有绑定 handler \tdeployment.GET(\u0026#34;/\u0026#34;) // 针对特定的命名资源操作 \t// 直接返回 找不到 \tdeployment.GET(\u0026#34;/:name\u0026#34;, func(c *gin.Context) { err := errors.New(\u0026#34;deployment not found\u0026#34;) httpresponse.Error(c, http.StatusNotFound, err) }) } } http response     对于应答消息， 不建议将 成功 和 失败 内容分成两个不同的 结构体 发送给客户端， 否则客户端在使用的时候还需要在判断应答的结构体属于哪种。 如果服务端一旦修改了应答结构体，客户端可能就崩掉了。\n// 成功 { \u0026quot;data\u0026quot;:\u0026quot;success data\u0026quot; } // 失败 { \u0026quot;error\u0026quot;:\u0026quot;error message\u0026quot; } 因此需要对 http 相应进行一些简单的封装。\n  把应答消息封装成一个标准结构， 具体消息信息用某个字段占有。\n data 表示成功消息 error 表示失败消息    http status code 本身就对 行为和资源 的有了一个明确的描述， 并且是通用的。 因此最好能将 response code 和 http status code 之间建立一个映射关系， 这样通过 code 也快速的判断 response 状态和内容。\n 这里只是简单的将 http status code 用作 response code 。 如果 http code 是 200， 则 response code 强制设置成 0。 一般情况下，非 0 表示异常。    /pkg/confgin/httpresponse/response.go\nfunc Common(c *gin.Context, code int, data interface{}, err error) { _err := \u0026#34;\u0026#34; if err != nil { _err = err.Error() } // 强制设置 \tif code == 200 { code = 0 } resp := Response{ Code: code, Data: data, Error: _err, } c.JSON(code, resp) } 文献      gitlab RESTful API: https://docs.gitlab.com/ee/api/api_resources.html github RESTful API: https://docs.github.com/en/rest/overview/resources-in-the-rest-api kalaserach resp api 最佳实践: https://kalasearch.cn/blog/rest-api-best-practices/  运行起来     启动服务     cd cmd/k8sailor \u0026amp;\u0026amp; go run . httpserver [GIN-debug] GET /k8sailor/v0/ping --\u0026gt; github.com/tangx/k8sailor/cmd/k8sailor/apis.RootGroup.func1 (3 handlers) [GIN-debug] GET /k8sailor/v0/deployments/ --\u0026gt; github.com/gin-gonic/gin.CustomRecoveryWithWriter.func1 (2 handlers) [GIN-debug] GET /k8sailor/v0/deployments/:name --\u0026gt; github.com/tangx/k8sailor/cmd/k8sailor/apis.RootGroup.func2 (3 handlers) [GIN-debug] Listening and serving HTTP on :8088 请求接口     这里推荐一个 vscode 下比较好用的 http client REST client, 类似 postman\n https://marketplace.visualstudio.com/items?itemName=humao.rest-client\n ### GET deployment by name GET http://127.0.0.1:8088/k8sailor/v0/deployments/my-nginx-01 请求结果， 资源找不到， http status code, data code 等都符合预期。\nHTTP/1.1 404 Not Found Content-Type: application/json; charset=utf-8 Date: Fri, 24 Sep 2021 03:18:34 GMT Content-Length: 55 Connection: close { \u0026#34;code\u0026#34;: 404, \u0026#34;data\u0026#34;: null, \u0026#34;error\u0026#34;: \u0026#34;deployment not found\u0026#34; } ","description":"RESTful-API 与 http-response-data      tag: https://github.com/tangx/k8sailor/tree/feat/05-design-restful-api-and-response-data\n 强烈建议使用 RESTful 风格来设计 API 文档。\nRESTful api     # kubectl create deployment nginx-tools --image nginx:alpine --output=yaml --dry-run=clientapiVersion:apps/v1kind:Deploymentmetadata:creationTimestamp:nulllabels:app:nginx-toolsname:nginx-tools# ... 省略# kubectl create namespace hello --dry-run=client -o yamlapiVersion:v1kind:Namespacemetadata:creationTimestamp:nullname:hello# ... 省略可以看到， k8s api 中都有一个对应的 kind 描述资源类型， 这个正好符合 RESTful 中资源定位的需求。\n大概就是这样。\n# 所有资源操作 GET /appname/v0/:resources ## 特定志愿操作 GET /appname/v0/:resources/:name?params POST /appname/v0/:resources/:name?params DELETE /appname/v0/:resources/:name # 获取所有 deployemnt 信息, 默认会设计一些限定条件， 比如说 namespace=default GET /k8sailor/v0/deployments # 针对特定名称资源的 deployment 操作 GET /k8sailor/v0/deployments/my-nginx-01?"},{"id":6,"href":"/books/k8sailor/chapter02/06-get-all-deployments/","title":"06 Get All Deployments","parent":"Chapter02","content":"使用 api/biz/dao 分层结构管理数据请求，获取 deployment 数据      tag: https://github.com/tangx/k8sailor/tree/feat/06-get-all-deployments\n client -\u0026gt; apis -\u0026gt; biz -\u0026gt; dao -\u0026gt; 将业务逻辑部分分为经典三层，想法是这样的，可能实现有错误。\n apis 接入层: 只用于管理 http 请求与交互。 biz 业务层: 用于处理 api 层来的请求， 封装原始数据 dao 数据访问层: 与数据库, cluster 等交互。 存取数据。  重新调整目录结构      新创建 /internal 目录用于存放业务信息 在 /internal 目录下新创建 业务层 /internal/biz 和 k8s dao 层 /internal/k8sdao 将 apis 接入层 从原来的 /cmd/k8sailor/apis 移动到了 /internal/apis  使用 jarvis, 删除 cobra flags      统一使用 jarvis 进行变量管理， 因此删除了 global/config.go 和 k8s/cluster.go 原来的 flag 相关变量声明使用的代码 但 cobra cmd 命令相关代码依旧保留， 感觉以后会用到。 将原来的 /pkg/k8s 重命名为 /pkg/confk8s， 命名风格更加统一。  获取 deployments 信息      api 处理用户请求参数， 请求 biz Operator 方法 biz Operator， 请求 k8sdao Operator， 并 处理/过滤 原始数据 k8sdao 与 cluster 交互， 返回原始数据。   有点问题， 三个模块， 三次同名方法。 有点麻烦。\n kubernete.ClientSet 客户端     在 /cmd/k8sailor/global/config.go 中声明 KubeClient\n并在 /internal/k8sdao/clientset.go 包中赋值给新变量名保存， 使用短名字方便后续调用。\nvar clientset = global.KubeClient.Client() 在 dao 层获取 deployment 数据     在 /internal/k8sdao/deployments.go 中， 封装了一个 获取指定 namespace 所有 Pod 的方法。 并返回给下游\nfunc GetAllDeployments(namespace string) ([]appsv1.Deployment, error) { ctx := context.TODO() opts := metav1.ListOptions{} v1Deps, err := clientset.AppsV1().Deployments(namespace).List(ctx, opts) if err != nil { return nil, err } return v1Deps.Items, nil } 在 biz 层提取 dao 层原始数据     在 业务层 ， 调用 dao 层的 api 获取 k8s cluster 的原始数据， 并根据业务世纪需求提取必要信息形成 新的业务层的 Deployment 对象， 并返回给用户。\n之前还真不知道， deployment 中有如此多的 replicas 字段（这里还没列举完）\ntype Deployment struct { Name string `json:\u0026#34;name\u0026#34;` Namespace string `json:\u0026#34;namespace\u0026#34;` // Replicas 实际期望的 pod 数量 \tReplicas int32 `json:\u0026#34;replicas\u0026#34;` // 镜像列表 \tImages []string `json:\u0026#34;images\u0026#34;` Status DeploymentStatus `json:\u0026#34;status\u0026#34;` } type DeploymentStatus struct { // 标签匹配的 Pod 数量 \tReplicas int32 `json:\u0026#34;replicas\u0026#34;` // 可用 pod 数量 \tAvailableReplicas int32 `json:\u0026#34;availableReplicas\u0026#34;` // 不可用数量 \tUnavailableReplicas int32 `json:\u0026#34;unavailableReplicas\u0026#34;` } 同样是在这里， 定义了业务层中 每个方法 的请求参数。\ntype GetAllDeploymentsInput struct { Namespace string `query:\u0026#34;namespace\u0026#34;` } // GetAllDeployments 获取 namespace 下的所有 deployments func GetAllDeployments(input GetAllDeploymentsInput) ([]Deployment, error) { v1Deps, err := k8sdao.GetAllDeployments(input.Namespace) // ... 省略 } apis 接入层处理用户请求， 返回用户需要的数据     在 apis 接入层中， 定义了各个请求的 方法、路由和处理器（hanlder）。\n同时也将用户请求绑定到 biz 中的 方法请求参数 上。\nfunc handlerGetAllDeployments(c *gin.Context) { params := \u0026amp;deployment.GetAllDeploymentsInput{} // 绑定用户请求参数 \terr := ginbinder.ShouldBindRequest(c, params) if err != nil { httpresponse.Error(c, http.StatusBadRequest, err) return } // ...省略 } ginbinder 是针对 gin 框架封装的一个请求数据绑定库， 可以方便的将 http request 中的请求参数 一次性全部 绑定到 接收者(params) 中\n跑起来     使用 make httpserver 命令启动 server 服务\n[GIN-debug] GET /k8sailor/v0/ping --\u0026gt; github.com/tangx/k8sailor/internal/apis.RootGroup.func1 (3 handlers) [GIN-debug] GET /k8sailor/v0/deployments/ --\u0026gt; github.com/tangx/k8sailor/internal/apis.handlerGetAllDeployments (3 handlers) [GIN-debug] GET /k8sailor/v0/deployments/:name --\u0026gt; github.com/tangx/k8sailor/internal/apis.DeploymentRouterGroup.func1 (3 handlers) [GIN-debug] Listening and serving HTTP on :8088 使用 vscode REST client 请求 /k8sailor/v0/deployments/ 接口\n### GET all deployments GET http://127.0.0.1:8088/k8sailor/v0/deployments?namespace=default 结果与期望一致\nHTTP/1.1 200 OK Content-Type: application/json; charset=utf-8 Date: Fri, 24 Sep 2021 18:05:39 GMT Content-Length: 336 Connection: close { \u0026quot;code\u0026quot;: 0, \u0026quot;data\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;my-nginx-1\u0026quot;, \u0026quot;namespace\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;replicas\u0026quot;: 1, \u0026quot;images\u0026quot;: [ \u0026quot;nginx:alpine\u0026quot; ], \u0026quot;status\u0026quot;: { \u0026quot;replicas\u0026quot;: 1, \u0026quot;availableReplicas\u0026quot;: 1, \u0026quot;unavailableReplicas\u0026quot;: 0 } }, { \u0026quot;name\u0026quot;: \u0026quot;my-nginx-2\u0026quot;, \u0026quot;namespace\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;replicas\u0026quot;: 2, \u0026quot;images\u0026quot;: [ \u0026quot;nginx:alpine\u0026quot; ], \u0026quot;status\u0026quot;: { \u0026quot;replicas\u0026quot;: 2, \u0026quot;availableReplicas\u0026quot;: 2, \u0026quot;unavailableReplicas\u0026quot;: 0 } } ], \u0026quot;error\u0026quot;: \u0026quot;\u0026quot; } Next     现在数据有了， 接下来要使用 vue3+typescript 在前端展示了。 想想都头疼。\n","description":"使用 api/biz/dao 分层结构管理数据请求，获取 deployment 数据      tag: https://github.com/tangx/k8sailor/tree/feat/06-get-all-deployments\n client -\u0026gt; apis -\u0026gt; biz -\u0026gt; dao -\u0026gt; 将业务逻辑部分分为经典三层，想法是这样的，可能实现有错误。\n apis 接入层: 只用于管理 http 请求与交互。 biz 业务层: 用于处理 api 层来的请求， 封装原始数据 dao 数据访问层: 与数据库, cluster 等交互。 存取数据。  重新调整目录结构      新创建 /internal 目录用于存放业务信息 在 /internal 目录下新创建 业务层 /internal/biz 和 k8s dao 层 /internal/k8sdao 将 apis 接入层 从原来的 /cmd/k8sailor/apis 移动到了 /internal/apis  使用 jarvis, 删除 cobra flags      统一使用 jarvis 进行变量管理， 因此删除了 global/config."},{"id":7,"href":"/books/k8sailor/chapter02/07-initial-vue3-vite2/","title":"07 Initial Vue3 Vite2","parent":"Chapter02","content":"初始化 vue3+vite     安装     # 初始化项目 yarn create vite webapp --template vue-ts cd webapp ## 安装依赖 yarn ## 启动查看 vue3 是否正常 yarn dev ## 安装 less 支持， 以后写样式用 yarn add less 清理环境      删除 /webapp/src/components 下的 HelloWorld.vue。 并新建一个 Deployment.vue。 这里使用 vue3 的 setup 语法糖。  在 \u0026lt;template\u0026gt; 标签对中创建内容 \u0026lt;h3\u0026gt;hello deployments\u0026lt;/h3\u0026gt;\n\u0026lt;template\u0026gt; \u0026lt;h3\u0026gt;hello deployments\u0026lt;/h3\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script setup lang=\u0026#39;ts\u0026#39;\u0026gt; \u0026lt;/script\u0026gt; \u0026lt;style lang=\u0026#39;less\u0026#39; scoped\u0026gt; \u0026lt;/style\u0026gt; 修改 /webapp/src/App.vue, 将与 HelloWorld 相关的内容全部替换成 Deployment  \u0026lt;template\u0026gt; \u0026lt;Deployment/\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script setup lang=\u0026#34;ts\u0026#34;\u0026gt; import Deployment from \u0026#39;./components/Deployment.vue\u0026#39; \u0026lt;/script\u0026gt; 运行 webapp 查看效果  yarn dev  朴实无华的界面。\n","description":"初始化 vue3+vite     安装     # 初始化项目 yarn create vite webapp --template vue-ts cd webapp ## 安装依赖 yarn ## 启动查看 vue3 是否正常 yarn dev ## 安装 less 支持， 以后写样式用 yarn add less 清理环境      删除 /webapp/src/components 下的 HelloWorld.vue。 并新建一个 Deployment.vue。 这里使用 vue3 的 setup 语法糖。  在 \u0026lt;template\u0026gt; 标签对中创建内容 \u0026lt;h3\u0026gt;hello deployments\u0026lt;/h3\u0026gt;\n\u0026lt;template\u0026gt; \u0026lt;h3\u0026gt;hello deployments\u0026lt;/h3\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script setup lang=\u0026#39;ts\u0026#39;\u0026gt; \u0026lt;/script\u0026gt; \u0026lt;style lang=\u0026#39;less\u0026#39; scoped\u0026gt; \u0026lt;/style\u0026gt; 修改 /webapp/src/App."},{"id":8,"href":"/books/k8sailor/chapter02/08-fetch-and-display-deployments/","title":"08 Fetch and Display Deployments","parent":"Chapter02","content":"获取并展示 Deployments 信息      tag: https://github.com/tangx/k8sailor/tree/feat/08-fetch-and-display-deployments\n   使用 Axios 请求 Deployments 数据     安装 axios 客户端\n# 安装 axios yarn add axios 创建 /webapp/src/apis 目录， 用于存放所有针对 k8sailor 后端的数据请求\n使用 axios config 模式初始化一个客户端     /webapp/src/apis/httpc.ts\naxios config 模式可以创建一个 http 客户端，其中包含了各种各样的初始化参数， 使用这个模式就不用在每个请求中都写重复的内容了。\nimport axios from \u0026#39;axios\u0026#39; // 使用 config 模式 // https://github.com/axios/axios#config-defaults let httpc = axios.create({ baseURL:\u0026#34;http://127.0.0.1:8088/k8sailor/v0\u0026#34; }) export default httpc 创建 deployments 的请求参数     /webapp/src/apis/deployment.ts\n有了公共的 httpc 之后， 在不同的 组建 中就可以直接 import 使用了。\n 注意: 在 httpc.get() 的时候， 只写了 deployments 的接口相对地址。 在发送请求是， axsio 会自动进行补全。\n import httpc from \u0026#39;./httpc\u0026#39; // 获取所有 deployment 信息 // namespace 默认值为 defualt // 使用 async await 解析内容 async function getAllDeployments(namespace = \u0026#34;default\u0026#34;): Promise\u0026lt;Deployment\u0026gt;{ const resp = await httpc.get(`/deployments?namespace=${namespace}`) // console.log(resp.data)  return resp.data } server 端允许 cors 跨域     到这里会遇到 跨域 问题。 由于目前 前后端 是分离的，并且之前我们在 server 并没有相关代码允许跨域请求。 所有通过页面的请求 暂时 是无法拿到数据的。\n跨域在 gin 中的实现其实就是 gin.HandlerFunc， 可以理解成一种中间件。\n以下是跨域规则， 规则比较暴力， 极狐允许了全部请求， 在实际使用中， 可以进行按需调整。\nfunc cors() gin.HandlerFunc { return func(c *gin.Context) { method := c.Request.Method if method != \u0026#34;\u0026#34; { c.Header(\u0026#34;Access-Control-Allow-Origin\u0026#34;, \u0026#34;*\u0026#34;) // 可将将 * 替换为指定的域名 \tc.Header(\u0026#34;Access-Control-Allow-Methods\u0026#34;, \u0026#34;POST, GET, OPTIONS, PUT, DELETE, UPDATE\u0026#34;) c.Header(\u0026#34;Access-Control-Allow-Headers\u0026#34;, \u0026#34;Origin, X-Requested-With, Content-Type, Accept, Authorization,X-Token\u0026#34;) c.Header(\u0026#34;Access-Control-Expose-Headers\u0026#34;, \u0026#34;Content-Length, Access-Control-Allow-Origin, Access-Control-Allow-Headers, Cache-Control, Content-Language, Content-Type\u0026#34;) c.Header(\u0026#34;Access-Control-Allow-Credentials\u0026#34;, \u0026#34;true\u0026#34;) } if method == \u0026#34;OPTIONS\u0026#34; { c.AbortWithStatus(http.StatusNoContent) } } } 接下来在 server 端应用规则， 允许跨域。\n// RegisterRoute 注册 func (s *Server) RegisterRoute(registerFunc func(rg *gin.RouterGroup)) { // 注册以服务名为根的路由信息，方便在 k8s ingress 中做转发 \tbase := s.engine.Group(s.Appname) // 针对 appname 下的路由，允许跨域 \tbase.Use(cors()) // 注册业务子路由 \tregisterFunc(base) } 这里并没有在 根路由 下允许， 而是在 /:appname 下允许。\n也就是说如下\n# 允许跨域 /appname/deployments /appname/pods/:podname # 不允许跨域 /ping vue3 展示数据     使用 reactive 定义一个 响应式 数据\n\u0026lt;script setup lang=\u0026#39;ts\u0026#39;\u0026gt; import {reactive } from \u0026#39;@vue/reactivity\u0026#39; import client,{ DeploymentItem } from \u0026#39;../apis/deployment\u0026#39; let data = reactive({ namespace:\u0026#34;default\u0026#34;, error: \u0026#34;\u0026#34;, items: [] as DeploymentItem[] }) \u0026lt;/script\u0026gt; 使用 onMounted 加载数据     onMounted 是 vue3 的生命周期钩子的其中一个, 在页面加载时执行。\n https://v3.vuejs.org/guide/composition-api-lifecycle-hooks.html\n \u0026lt;script setup lang=\u0026#39;ts\u0026#39;\u0026gt; import {reactive } from \u0026#39;@vue/reactivity\u0026#39; import { onMounted } from \u0026#39;@vue/runtime-core\u0026#39; // ...  onMounted(()=\u0026gt;{ getAllByNamespace() }) \u0026lt;/script\u0026gt; 使用 v-for 显示数据     \u0026lt;tr v-for=\u0026#34;(item,id) in data.items\u0026#34; key=:id\u0026gt; \u0026lt;th scope=\u0026#34;row\u0026#34;\u0026gt;{{ id }}\u0026lt;/th\u0026gt; \u0026lt;td\u0026gt;{{ item.name }}\u0026lt;/td\u0026gt; \u0026lt;!-- 省略 --\u0026gt; \u0026lt;/tr\u0026gt; 使用 v-if 进行条件渲染     在返回的数据中， 有两种状况:\n 有错误， 没数据 没错误， 有数据  因此设置了两个容器（错误与表格）， 使用 v-if 根据是否有错误消息决定是否展示这两部分容器\n\u0026lt;!-- 当数据异常的时候显示 --\u0026gt; \u0026lt;div class=\u0026#34;error-container\u0026#34; v-if=\u0026#34;data.error\u0026#34;\u0026gt; \u0026lt;!-- 省略 --\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!-- 当数据正常的时候显示 --\u0026gt; \u0026lt;table class=\u0026#34;table\u0026#34; v-if=\u0026#34;!data.error\u0026#34;\u0026gt; \u0026lt;!-- 省略 --\u0026gt; \u0026lt;/table\u0026gt; 使用 v-model 绑定数据     v-model 数据的双向绑定。 v-model=\u0026quot;data.source\u0026quot; 是将 data.source 的值绑定到 控件 的 value 属性上。\n\u0026lt;input type=\u0026#34;text\u0026#34; placeholder=\u0026#34;default\u0026#34; v-model=\u0026#34;data.namespace\u0026#34;\u0026gt; 使用 v-on 绑定事件     @ 是 v-on 的语法糖， 因此@click 完全写法就是 v-on=click。 意思就是 点击按钮 触发 getAllByNamespace 方法。\n\u0026lt;button @click=\u0026#34;getAllByNamespace(data.namespace)\u0026#34;\u0026gt;更新数据\u0026lt;/button\u0026gt; 问题遗留     301 重定向遇到跨域问题。     ","description":"获取并展示 Deployments 信息      tag: https://github.com/tangx/k8sailor/tree/feat/08-fetch-and-display-deployments\n   使用 Axios 请求 Deployments 数据     安装 axios 客户端\n# 安装 axios yarn add axios 创建 /webapp/src/apis 目录， 用于存放所有针对 k8sailor 后端的数据请求\n使用 axios config 模式初始化一个客户端     /webapp/src/apis/httpc.ts\naxios config 模式可以创建一个 http 客户端，其中包含了各种各样的初始化参数， 使用这个模式就不用在每个请求中都写重复的内容了。\nimport axios from \u0026#39;axios\u0026#39; // 使用 config 模式 // https://github.com/axios/axios#config-defaults let httpc = axios.create({ baseURL:\u0026#34;http://127.0.0.1:8088/k8sailor/v0\u0026#34; }) export default httpc 创建 deployments 的请求参数     /webapp/src/apis/deployment."},{"id":9,"href":"/books/k8sailor/chapter02/09-get-pods-by-deployment-label/","title":"09 Get Pods by Deployment Label","parent":"Chapter02","content":"通过 deployment label 获取 pod 信息      tag: https://github.com/tangx/k8sailor/tree/feat/09-get-pods-by-deployment-label\n 有了之前结构铺垫， 获取 Pod 还是很简单简单的。 其中需要注意的是 ListOptions 中的 LabelSelector 是一个字符串， 多组 key=value 之间使用 逗号 , 进行连接。\nlabelSelector := `key1=value1,key2=value2,...` 而通过 client-go API 获取的 Deployment, Pod 等信息中的 MatchLabel 字段是一个 map[string]string 的 map。\n因此， 在使用 k8s client 查询的时候， 需要对进行一些传参转换。\n// convertMapToSelector convert map to string, use comma connection: k1=v1,k2=v2 func convertMapToSelector(labels map[string]string) string { l := []string{} for k, v := range labels { l = append(l, fmt.Sprintf(\u0026#34;%s=%s\u0026#34;, k, v)) } return strings.Join(l, \u0026#34;,\u0026#34;) } 获取 Pod     Pod 本身是 k8s 的一个最核心的概念， 独立于其他 Workloads ， 这点从 API 上也可以看出来。 Pod 的 API 是 core v1 而 Deployment 是 apps v1。\n可以直接通过 Label 获取 Pod 信息\n/internal/k8sdao/pod.go\nfunc GetPodByLabels(ctx context.Context, namespace string, labels map[string]string) (*corev1.PodList, error) { opts := metav1.ListOptions{ LabelSelector: convertMapToSelector(labels), } return clientset.CoreV1().Pods(namespace).List(ctx, opts) } 通过 Deployment 获取 Pod     Pod 与其他 Workloads 之间的关联是 弱关联 / 间接关联， 以 Deployment 为例。 Deployment 创建 ReplicaSet, ReplicaSet 创建 Pod\n首先， 通过 clientset 的 Get 方法根据 Name 获取到 Deployment 对象， 在通过 Deployment 中的 Label 信息获取对应的 Pod 对象。 这里需要注意的是上述所讲的的 Pod 与 Deployment 之间的弱关联关系， 因为是通过标签匹配的，所以结果可能根本与 Deployment 无关。\n假如现在有两个 Deployment 如下\n# dep1kind:Deploymentmetadata:creationTimestamp:nulllabels:# 只有一组标签app:my-nginx-1name:my-nginx-1# ... 省略---# dep2kind:Deploymentmetadata:creationTimestamp:nulllabels:# 有两组标签， 其中 app 组与 dep1 相同app:my-nginx-1srv:my-nginx-2name:my-nginx-2## ... 省略如果单独的通过 app=my-nginx-1 标签来匹配，还会得到 dep2 的 Pod\nkubectl get pod -l app=my-nginx-1 获取 ReplicaSet 再获取 Pod     /internal/k8sdao/replicaset.go\n因此， 在获取获取 Pod 信息之前， 应该先获取 ReplicaSet， 再获取 Pod\n通过 deployment 的 label 获取 ReplicaSet\n# kubectl get rs -l app=my-nginx-1 NAME DESIRED CURRENT READY AGE my-nginx-1-6d9577949b 1 1 1 4d14h 得到 rs 详细信息如下\n# kubectl get rs -o yaml my-nginx-1-6d9577949bapiVersion:apps/v1kind:ReplicaSetmetadata:# ... 省略labels:app:my-nginx-1pod-template-hash:6d9577949b# ... 省略通过带有 rs 的 label 进行查询\n# kubectl pod -l app=my-nginx-1,pod-template-hash=6d9577949b NAME READY STATUS RESTARTS AGE my-nginx-1-6d9577949b-bhwlp 1/1 Running 0 4d14h 查询出来的 Pod 结果符合预期\n# kubectl get pod my-nginx-1-6d9577949b-bhwlp -o yamlapiVersion:v1kind:Podmetadata:creationTimestamp:\u0026#34;2021-09-23T16:13:51Z\u0026#34;generateName:my-nginx-1-6d9577949b-labels:app:my-nginx-1pod-template-hash:6d9577949b# ... 省略","description":"通过 deployment label 获取 pod 信息      tag: https://github.com/tangx/k8sailor/tree/feat/09-get-pods-by-deployment-label\n 有了之前结构铺垫， 获取 Pod 还是很简单简单的。 其中需要注意的是 ListOptions 中的 LabelSelector 是一个字符串， 多组 key=value 之间使用 逗号 , 进行连接。\nlabelSelector := `key1=value1,key2=value2,...` 而通过 client-go API 获取的 Deployment, Pod 等信息中的 MatchLabel 字段是一个 map[string]string 的 map。\n因此， 在使用 k8s client 查询的时候， 需要对进行一些传参转换。\n// convertMapToSelector convert map to string, use comma connection: k1=v1,k2=v2 func convertMapToSelector(labels map[string]string) string { l := []string{} for k, v := range labels { l = append(l, fmt."},{"id":10,"href":"/books/k8sailor/chapter02/10-vue-router-and-less/","title":"10 Vue Router and Less","parent":"Chapter02","content":"使用 vue-router 进行路由管理      tag: https://github.com/tangx/k8sailor/tree/feat/10-vue-router-and-less\n  使用 vue-router 路由管理     安装 vue-router 支持参考 https://tangx.in/2021/09/28/vue3-vue-router/\n  将默认的 /webapp/src/App.vue 作为最基本的入口， 除了引入 Index.vue 文件模块，不进行其他操作， 保持整洁。 其行为类似 golang 中的 main.go。\n  创建 /webapp/src/components/Index.vue 模块作为 index 入口文件， 也是主要的布局页面。\n 路由信息(router-link) 将放置在页面左侧 路由展示(router-view) 作为占位符放在右侧。    所有数据展示类模块都放在 /webapp/src/components/views 目录下。 所有内容将通过 vue-router 组件渲染， 展示在 Index.vue 模块的 router-view 区域。\n  使用 less 进行 Index 部署     less https://lesscss.org/ 是 css 的超级。 不仅语法与 css 相同。 而且支持 嵌套 书写， 可以直观的展现组件之间的层级关系。\ndiv 本身是 行元素 ， 即 一个 div 就需要占用一行。 在 css 布局中使用 display: flex; 后将脱离数据流， 悬浮并排在一起。 默认为水平排列。\n配合使用 flex-direction: column; 将垂直排列。\n\u0026lt;style lang='less' scoped\u0026gt; .body{ // body 子元素悬浮水平排列 display: flex; .body-left{ width: 20%; margin: 5px; .link-container{ // 垂直排列 display: flex; flex-direction: column; } } } \u0026lt;/style\u0026gt;  flex: https://developer.mozilla.org/zh-CN./Web/CSS/CSS_Flexible_Box_Layout/Basic_Concepts_of_Flexbox\n ","description":"使用 vue-router 进行路由管理      tag: https://github.com/tangx/k8sailor/tree/feat/10-vue-router-and-less\n  使用 vue-router 路由管理     安装 vue-router 支持参考 https://tangx.in/2021/09/28/vue3-vue-router/\n  将默认的 /webapp/src/App.vue 作为最基本的入口， 除了引入 Index.vue 文件模块，不进行其他操作， 保持整洁。 其行为类似 golang 中的 main.go。\n  创建 /webapp/src/components/Index.vue 模块作为 index 入口文件， 也是主要的布局页面。\n 路由信息(router-link) 将放置在页面左侧 路由展示(router-view) 作为占位符放在右侧。    所有数据展示类模块都放在 /webapp/src/components/views 目录下。 所有内容将通过 vue-router 组件渲染， 展示在 Index.vue 模块的 router-view 区域。\n  使用 less 进行 Index 部署     less https://lesscss."},{"id":11,"href":"/books/k8sailor/chapter02/11-display-deployment-detail/","title":"11 Display Deployment Detail","parent":"Chapter02","content":"展示 deployment 详情页      tag: https://github.com/tangx/k8sailor/tree/feat/11-display-deployment-detail\n  之前在后端已经将详情页的展示接口拆成了 2个\n 其一是根据 name 获取 单个 deployment /deployments/:name 其二是根据 deployment name 获取 关联 的 pods 信息 /deployments/:name/pod  页面展示就是两个接口请求与数据展示的简单操作， 和之前 deployment 页面一样， 没什么好说的。\ntypescript 的 interface 衍生     不过， 在遇到第二个、第三个接口出现的时候， 发现之前对于 deployment list 返回的数据结构设计出现了问题。\n当时是将 code, error 两个字段直接内嵌到 Deployment 的接口设计之中。\nexport interface Deployment { code: number error: string data: DeploymentItem[] } export interface DeploymentItem { images: string[] name: string namespace: string replicas: number status: { availableReplicas: number replicas: number unavailableReplicas: number } } 现在发现， 如果需要在对 单 Deployment 和 多 Pod 进行返回的时候， 再重复这样将 code, error 耦合到响应接口里面就额外的冗余了。\n因此， 在 /webapp/src/apis/httpc.ts 中单独抽象了一个 根响应接口 HttpcResponse， 包含了 code 和 error 字段。\n// HttpcResponse 是 Server 端的基础响应结构体 // 具体的接口响应结果， 需要接口自行实现 HttpcReponse 的继承与 data 字段的覆盖 export interface HttpcResponse { code: number error: string data: Object } 之后具体的接口响应接口， 都从 HttpcResponse 中衍生， 其行为只需要覆盖 data 字段即可。\n// Deployment 定义 Deployment 数据字段 export interface Deployment { images: string[] name: string namespace: string replicas: number status: { availableReplicas: number replicas: number unavailableReplicas: number } } // DeploymentListResponse 继承并覆盖 data， 返回 deployment 的列表 export interface DeploymentListResponse extends HttpcResponse { data: Deployment[] } // DeploymentResponse 继承并覆盖 data， 返回 deployment 的单个字段 export interface DeploymentResponse extends HttpcResponse { data: Deployment } vue3 获取路由信息      https://next.router.vuejs.org/zh/api/#currentroute\n 在 vue3 setup 语法中， 倒入 vue-router 模块， 使用 useRouter() 方法获取到 router API。\n就可以很方便的通过 router.currentRouter 获取到相关路由信息了。\n// 路由表 const routes = [ { path: \u0026#34;/deployments/:name\u0026#34;, name: \u0026#34;DeploymentDetail\u0026#34;, component: () =\u0026gt; import(\u0026#39;@/components/views/DeploymentDetail.vue\u0026#39;) } ] 之前在路由表中定义路由信息的时候， 使用了 /deployments/:name 路径参数， 也是在这里的路由中获取。\nimport { useRouter } from \u0026#34;vue-router\u0026#34;; const router = useRouter() // 获取 url 中的变量信息 const fetchUrlParams = function () { // 获取全路径  // console.log(\u0026#34;fullpath::::\u0026#34;,router.currentRoute.value.fullPath);  // 获取 query 参数  // console.log(\u0026#34;query::::\u0026#34;,router.currentRoute.value.query);  // 获取 路径参数  // console.log(\u0026#34;params::::\u0026#34;,router.currentRoute.value.params);  req.Params.name = router.currentRoute.value.params.name as string req.Params.namespace = router.currentRoute.value.query.namespace as string } ","description":"展示 deployment 详情页      tag: https://github.com/tangx/k8sailor/tree/feat/11-display-deployment-detail\n  之前在后端已经将详情页的展示接口拆成了 2个\n 其一是根据 name 获取 单个 deployment /deployments/:name 其二是根据 deployment name 获取 关联 的 pods 信息 /deployments/:name/pod  页面展示就是两个接口请求与数据展示的简单操作， 和之前 deployment 页面一样， 没什么好说的。\ntypescript 的 interface 衍生     不过， 在遇到第二个、第三个接口出现的时候， 发现之前对于 deployment list 返回的数据结构设计出现了问题。\n当时是将 code, error 两个字段直接内嵌到 Deployment 的接口设计之中。\nexport interface Deployment { code: number error: string data: DeploymentItem[] } export interface DeploymentItem { images: string[] name: string namespace: string replicas: number status: { availableReplicas: number replicas: number unavailableReplicas: number } } 现在发现， 如果需要在对 单 Deployment 和 多 Pod 进行返回的时候， 再重复这样将 code, error 耦合到响应接口里面就额外的冗余了。"},{"id":12,"href":"/books/k8sailor/chapter02/12-deployment-scale-and-params-validate/","title":"12 Deployment Scale and Params Validate","parent":"Chapter02","content":"deployment 副本数量设置 与 参数的有效性验证      tag: https://github.com/tangx/k8sailor/tree/feat/12-deployment-scale-and-params-validate\n deployment scale     kubectl scale deployment my-nginx-1 --replicas 1 在 client-go sdk 中， scale 参数是一个对象， 因此不能直接传入 一个数字。\n 需要通过 GetScale() 方法获取到 *autoscalingv1.Scale 对象。 修改 Scale 对象中的 Replicas 数值。 使用 UpdateScale() 方法更新设置。  SetDeploymentReplicas\nparams validtor     参数验证在任何情况下都不能放松警惕， 尤其是 边界验证 和 0值混淆 。\n对于参数的验证， 可以自己在业务代码中实现， 也可以使用已有的公共库。 gin 默认使用的是 https://github.com/go-playground/validator\n// SetDeploymentReplicasInput 调整 deployment pod 数量参数 // Replicas 为了避免 **0值** 影响。 // 1. 使用为 *int 指针对象， 自行在业务逻辑中进行校验 // 2. 另外也可以使用， `binding` tag， 由 gin 框架的 valicator 帮忙校验。 https://github.com/go-playground/validator // Namespace 设置了默认值， 如果请求不提供将由 gin 框架自己填充。 type SetDeploymentReplicasInput struct { Namespace string `query:\u0026#34;namespace,default=default\u0026#34;` Name string `uri:\u0026#34;name\u0026#34;` Replicas *int `query:\u0026#34;replicas\u0026#34; binding:\u0026#34;required\u0026#34;` } gin cors     需要在 根 上使用 cors 跨域设置。\n如果在子路由上允许， put 的时候也会出现 404。\nvue axios     axios 怎么传递 query 参数， 而不是手动写 ?\n https://tangx.in/2021/09/29/typescript-convert-json-to-querystring/\n yarn add @types/qs qs 使用 qs.stringify(params) 进行序列化。\n","description":"deployment 副本数量设置 与 参数的有效性验证      tag: https://github.com/tangx/k8sailor/tree/feat/12-deployment-scale-and-params-validate\n deployment scale     kubectl scale deployment my-nginx-1 --replicas 1 在 client-go sdk 中， scale 参数是一个对象， 因此不能直接传入 一个数字。\n 需要通过 GetScale() 方法获取到 *autoscalingv1.Scale 对象。 修改 Scale 对象中的 Replicas 数值。 使用 UpdateScale() 方法更新设置。  SetDeploymentReplicas\nparams validtor     参数验证在任何情况下都不能放松警惕， 尤其是 边界验证 和 0值混淆 。\n对于参数的验证， 可以自己在业务代码中实现， 也可以使用已有的公共库。 gin 默认使用的是 https://github.com/go-playground/validator\n// SetDeploymentReplicasInput 调整 deployment pod 数量参数 // Replicas 为了避免 **0值** 影响。 // 1."},{"id":13,"href":"/books/k8sailor/chapter02/13-k8s-informer/","title":"13 K8s Informer","parent":"Chapter02","content":"k8s informer      tag: https://github.com/tangx/k8sailor/tree/feat/13-k8s-informer\n  从应用层面来说， 创建 informer 并启动之后就与 k8s cluster 创建了一个长链接并订阅了 某个资源 Resource 的变化。\n至于订阅后得到的数据要怎么用完全取决于订阅者的业务设计。\nShared Informer Factory 共享机制     Informer 又称为 Shared Informer，表明是可以共享使用的，在使用 client-go 写代码时，若同一资源的 Informer 被实例化太多次，每个 Informer 使用一个 Reflector，会运行过多的相同 ListAndWatch（即图中的第一步），太多重复的序列化和反序列化会导致 k8s API Server 负载过重。\n而 Shared Informer 通过对同一类资源 Informer 共享一个 Reflector 可以节约很多资源，这通过 map 数据结构即可实现这样一个共享 Informer 机制。\n// Start initializes all requested informers. func (f *sharedInformerFactory) Start(stopCh \u0026lt;-chan struct{}) { f.lock.Lock() defer f.lock.Unlock() for informerType, informer := range f.informers { if !f.startedInformers[informerType] { go informer.Run(stopCh) f.startedInformers[informerType] = true } } }   informer.Run(stopCh) : informer 在启动的时候需要传入一个 通知停止的 channel stopCh \u0026lt;-chan struct{}。 因此用户是可以 主动 关闭 informer 通道的。\n  所有 informer 都是通过 go 协程跑在后台的。\n  Shared Informer Factory 注册 infomers     上面提到， Shared Informer Factory 一个很重要的作用就是\n 管理注册 Informer 防止相同类型的 Infomer 重复注册  /pkg/confk8s/informer.go ， 在注册 Informer 的时候其实很还是很方便的。\n// WithEventHandlers 注册 handler func (inf *Informer) WithEventHandlers(handlers ...InformerEventHandler) *Informer { for _, handler := range handlers { kind := handler.InformerKind() switch kind { case \u0026#34;deployment\u0026#34;: inf.factory.Apps().V1().Deployments().Informer().AddEventHandler(handler) case \u0026#34;pod\u0026#34;: inf.factory.Core().V1().Pods().Informer().AddEventHandler(handler) } } return inf } informer event handler     所有的 informer handler 满足接口\ntype ResourceEventHandler interface { OnAdd(obj interface{}) OnUpdate(oldObj, newObj interface{}) OnDelete(obj interface{}) } 即处理 增 OnAdd, 改 OnUpdate, 删 OnDelete 三种事件。\n项目案例     例如在本项目中\n 在本地创建了一个名为 k8scache 的存储空间， 使用 k8s informer 订阅了 Deployment 的数据并保存到了 本地 /internal/k8scache/deployment.go 中的 DeploymentCache 对象中。 并对外提供 deployment 的查询功能。\n由于项目本地都存的是数据副本，只提供了 查询 namespace 下的所有数据， 根据 name 查询某个 deployment 这样简单的功能。 原本 k8s 通过 label 查询 这样 好用 功能， 目前也就无法再提供了。\n自此， biz 代码逻辑中与 Deployment 相关的查询使用的数据源都修改为 k8scache。\n// GetDeploymentByName 通过名称获取 deployment func GetDeploymentByName(ctx context.Context, input GetDeploymentByNameInput) (*Deployment, error) { /* k8s api 返回的数据 */ // v1dep, err := k8sdao.GetDeploymentByName(ctx, input.Namespace, input.Name)  /* 使用本地的 k8scache */ v1dep, err := k8scache.DepTank.GetDeploymentByName(ctx, input.Namespace, input.Name) if err != nil { return nil, err } dep := extractDeployment(*v1dep) return dep, nil } informer 启动     上面已经说了， 使用 informer 创建的是一个独立 应用/模块， 可以作为一个 模块存在于应用内部， 也可以作为一个 独立的应用。\n无论是怎么定义的， informer 的启动和关闭都 必须要 独立控制。\n本项目中是作为一个模块, 在启动 http server 之前进行启动。 /cmd/k8sailor/cmd/httpserver.go\nvar cmdHttpserver = \u0026amp;cobra.Command{ Use: \u0026#34;httpserver\u0026#34;, Long: \u0026#34;启动 web 服务器\u0026#34;, Run: func(cmd *cobra.Command, args []string) { // 启动 informer \trunInformer() // 启动服务 \trunHttpserver() }, } func runInformer() { clientset := global.KubeClient.Client() informer := global.KubeInformer.WithClientset(clientset) k8scache.RegisterHandlers(informer) informer.Start() } 分层后代码实现的问题     其实上述 切换数据源 的实现是有问题的。\n数据源的切换不应该是在 biz 中完成， 而是应该在 k8sdao 中进行。\n 从逻辑上来说 k8scache 和 k8s 是一层的， 都是数据的提供者。 DAO 的含义是 数据访问对象 data access object， 其职责就是对 来自不同数据源的相同数据 执行 适合自身业务逻辑的抽象和封装  扩展阅读      深入理解 k8s informer: https://cloudnative.to/blog/client-go-informer-source-code/\n ","description":"k8s informer      tag: https://github.com/tangx/k8sailor/tree/feat/13-k8s-informer\n  从应用层面来说， 创建 informer 并启动之后就与 k8s cluster 创建了一个长链接并订阅了 某个资源 Resource 的变化。\n至于订阅后得到的数据要怎么用完全取决于订阅者的业务设计。\nShared Informer Factory 共享机制     Informer 又称为 Shared Informer，表明是可以共享使用的，在使用 client-go 写代码时，若同一资源的 Informer 被实例化太多次，每个 Informer 使用一个 Reflector，会运行过多的相同 ListAndWatch（即图中的第一步），太多重复的序列化和反序列化会导致 k8s API Server 负载过重。\n而 Shared Informer 通过对同一类资源 Informer 共享一个 Reflector 可以节约很多资源，这通过 map 数据结构即可实现这样一个共享 Informer 机制。\n// Start initializes all requested informers. func (f *sharedInformerFactory) Start(stopCh \u0026lt;-chan struct{}) { f."},{"id":14,"href":"/books/k8sailor/chapter02/14-some-optimize/","title":"14 Some Optimize","parent":"Chapter02","content":"一些优化      tag: https://github.com/tangx/k8sailor/tree/feat/14-some-optimize\n 将 LabelSelector 转换为 Selector     client-go 提供了一个方法， 可以将 Resource 中的 LabelSelector 转换为 Selector, 并且 Selector 结构提供了一些常用的方法。 如 String\nimport ( metav1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; ) func() { selector, _ := metav1.LabelSelectorAsSelector(dep.Spec.Selector) x := selector.String() fmt.Println(x) }() 因此在使用 GetXXXByLabels 时， api 层 可以考虑 接收 map[string]string 类型的参数。 而在 biz 层应该将 不同类型 的参数 统一 转换为格式为 key1=value1,key2=value2 的 string 类型参数。 在 dao 层只接收 string 类型的 string。 这样就实现了前后一致性的问题。\n自动刷新前端数据     在 vue 中， 如果数据是 响应式 数据， 那么当数据发生变化后， vue 会自动对页面进行刷新。\n因此为了实现页面自动刷新， 需要保障：\n 循环获取新数据 解决新数据与老数据 内容一致，顺序不一致 导致的页面刷新。  循环任务     使用 while 循环请求接口不断请求数据， 需要注意的是\n 循环一定要设置 间隔时间， typescript 中没有 sleep 函数， 可以使用 Promise 替代实现 一定要设置 循环开关， 否则循环代码将一直在浏览器中的 后台任务 执行。 并且刷新一次就开启一个后台任务， 如果不加以限制， 机器风扇呜呜呜的转。 琢磨琢磨。 循环开关 可以放到页面的 onMount() / onUnMount() 两个 生命周期钩子 中实现。  let onOff = reactive({ loop: false }) const getAllByNamespaceLoop = async function () { while (onOff.loop) { let f = getAllByNamespace(\u0026#34;default\u0026#34;) // 间隔时间， ts 中没有 sleep 函数， 所以使用 Promise 实现  await new Promise(f =\u0026gt; setTimeout(f, 2000)); } } onMounted(() =\u0026gt; { onOff.loop = true console.log(\u0026#34;onMounted: onOFF.loop\u0026#34;, onOff.loop); getAllByNamespaceLoop() }) onUnmounted(() =\u0026gt; { onOff.loop = false console.log(\u0026#34;onUnmounted: onOFF.loop\u0026#34;, onOff.loop); }) 前端数据排序     typescript 中， 数组 Array 有一个方法 sort( fn(n1,n2):number )， 接收一个 排序函数 作为传参。\n该 排序函数 接收 两个参数 表示元素， 返回一个 数字 类型表示是否交换位置。\n// 对数组进行排序， 避免返回结果数据相同但顺序不同时， vue 不断重新渲染。  let _items = resp.data.sort( (n1: Deployment, n2: Deployment) =\u0026gt; { if (n1.name \u0026gt;= n2.name) { return 1 } return -1 } )  https://stackoverflow.com/a/21689268\n 使用 informer 订阅 k8s event     使用 infromer 订阅 Core/V1 的 event 事件， 与 EventsV1 的 event 事件略有区别， 大体一致。\nevents, err := clientset.EventsV1().Events(\u0026#34;default\u0026#34;).List(ctx, v1.ListOptions{}) events2, err := clientset.CoreV1().Events(\u0026#34;default\u0026#34;).List(ctx, v1.ListOptions{}) 提取 event 事件的如下信息\n\u0026#34;involvedObject\u0026#34;: { \u0026#34;kind\u0026#34;: \u0026#34;Pod\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;failed-nginx-6df5766f6d-vjn9n\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;8726d44b-06b1-4d1c-9bad-efebf3fbb556\u0026#34;, \u0026#34;apiVersion\u0026#34;: \u0026#34;v1\u0026#34;, \u0026#34;resourceVersion\u0026#34;: \u0026#34;685855\u0026#34;, \u0026#34;fieldPath\u0026#34;: \u0026#34;spec.containers{nginx}\u0026#34; }, \u0026#34;reason\u0026#34;: \u0026#34;BackOff\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Back-off pulling image \\\u0026#34;nginx:alpine-11\\\u0026#34;\u0026#34;, \u0026#34;source\u0026#34;: { \u0026#34;component\u0026#34;: \u0026#34;kubelet\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;tangxin-test\u0026#34; }, 并封装成一个 map[string]Message 的格式\nPodEvent[\u0026#34;pod-namesapce-podname\u0026#34;] = Message{ Reason: \u0026#34;BackOff\u0026#34;, Message: \u0026#34;Back-off pulling image \\\u0026#34;nginx:alpine-11\\\u0026#34;\u0026#34;, } defineProps 传入自定义类型     setup 语法中怎么使用 props 传递值      https://v3.vuejs.org/api/sfc-script-setup.html#defineprops-and-defineemits\n 传入一个对象      https://v3.vuejs.org/guide/component-props.html#passing-an-object\n \u0026lt;blog-post :author=\u0026#34;{ name: \u0026#39;Veronica\u0026#39;, company: \u0026#39;Veridian Dynamics\u0026#39; }\u0026#34; \u0026gt;\u0026lt;/blog-post\u0026gt; 如何传递自定义类型      https://v3.vuejs.org/api/options-data.html#props\n Props 支持 默认 的几种类型（全都是 vue 自定义的 interface，所以首写字母都是大写）。 以及自定义的类型\n type: can be one of the following native constructors: String, Number, Boolean, Array, Object, Date, Function, Symbol, any custom constructor function or an array of those. Will check if a prop has a given type, and will throw a warning if it doesn\u0026rsquo;t. More information on prop types.\n defineProps 使用 PropType 实现自定义类型支持      https://v3.vuejs.org/guide/typescript-support.html#annotating-props\n import { defineComponent, PropType } from \u0026#39;vue\u0026#39; interface Book { title: string author: string year: number } const Component = defineComponent({ props: { name: String, id: [Number, String], success: { type: String }, callback: { type: Function as PropType\u0026lt;() =\u0026gt; void\u0026gt; }, // 使用对象模式表述属性  book: { // 注意这里， 使用 PropType 定义 Constructor  type: Object as PropType\u0026lt;Book\u0026gt;, required: true }, metadata: { type: null // metadata is typed as any  } } })  https://stackoverflow.com/questions/64325502/vue-js-3-props-type-validation-with-custom-type/64325609 https://v3.vuejs.org/guide/component-props.html#type-checks  ","description":"一些优化      tag: https://github.com/tangx/k8sailor/tree/feat/14-some-optimize\n 将 LabelSelector 转换为 Selector     client-go 提供了一个方法， 可以将 Resource 中的 LabelSelector 转换为 Selector, 并且 Selector 结构提供了一些常用的方法。 如 String\nimport ( metav1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; ) func() { selector, _ := metav1.LabelSelectorAsSelector(dep.Spec.Selector) x := selector.String() fmt.Println(x) }() 因此在使用 GetXXXByLabels 时， api 层 可以考虑 接收 map[string]string 类型的参数。 而在 biz 层应该将 不同类型 的参数 统一 转换为格式为 key1=value1,key2=value2 的 string 类型参数。 在 dao 层只接收 string 类型的 string。 这样就实现了前后一致性的问题。"},{"id":15,"href":"/books/k8sailor/chapter02/15-delete-deployment-and-pod-by-name/","title":"15 Delete Deployment and Pod by Name","parent":"Chapter02","content":"根据名字删除 deployment 和 pod      tag: https://github.com/tangx/k8sailor/tree/feat/15-delete-deployment-and-pod-by-name\n 调用 k8s api 没什么好说的。\nk8sdao\nfunc DeleteDeploymentByName(ctx context.Context, namespace string, name string) error { opts := metav1.DeleteOptions{} return clientset.AppsV1().Deployments(namespace).Delete(ctx, name, opts) } biz\ntype DeleteDeploymentByNameInput struct { Name string `uri:\u0026#34;name\u0026#34;` Namespace string `query:\u0026#34;namespace\u0026#34;` } // DeleteDeploymentByName 根据名字删除 deployment func DeleteDeploymentByName(ctx context.Context, input DeleteDeploymentByNameInput) error { err := k8sdao.DeleteDeploymentByName(ctx, input.Namespace, input.Name) if err != nil { return fmt.Errorf(\u0026#34;k8s internal error: %w\u0026#34;, err) } return nil } api\nfunc handlerDeleteDeploymentByName(c *gin.Context) { input := deployment.DeleteDeploymentByNameInput{} if err := ginbinder.ShouldBindRequest(c, \u0026amp;input); err != nil { httpresponse.Error(c, http.StatusBadRequest, err) return } if err := deployment.DeleteDeploymentByName(c, input); err != nil { httpresponse.Error(c, http.StatusInternalServerError, err) return } httpresponse.OK(c, true) } ","description":"根据名字删除 deployment 和 pod      tag: https://github.com/tangx/k8sailor/tree/feat/15-delete-deployment-and-pod-by-name\n 调用 k8s api 没什么好说的。\nk8sdao\nfunc DeleteDeploymentByName(ctx context.Context, namespace string, name string) error { opts := metav1.DeleteOptions{} return clientset.AppsV1().Deployments(namespace).Delete(ctx, name, opts) } biz\ntype DeleteDeploymentByNameInput struct { Name string `uri:\u0026#34;name\u0026#34;` Namespace string `query:\u0026#34;namespace\u0026#34;` } // DeleteDeploymentByName 根据名字删除 deployment func DeleteDeploymentByName(ctx context.Context, input DeleteDeploymentByNameInput) error { err := k8sdao.DeleteDeploymentByName(ctx, input.Namespace, input.Name) if err != nil { return fmt.Errorf(\u0026#34;k8s internal error: %w\u0026#34;, err) } return nil } api"},{"id":16,"href":"/books/k8sailor/chapter02/16-create-deployment/","title":"16 Create Deployment","parent":"Chapter02","content":"创建 deployment      tag: https://github.com/tangx/k8sailor/tree/feat/16-create-deployment\n 使用 kubectl 命令创建如下\nkubectl create deployment my-nginx-5 --image=nginx:alpine --replicas=3 --port=80 创建成功后查看结果， 大部分参数为默认参数。\n# kgd -o yaml my-nginx-5apiVersion:apps/v1kind:Deploymentmetadata:labels:app:my-nginx-5# 根据 deployment 自动匹配名字自动生成name:my-nginx-5 # 用户指定namespace:default# 用户选择，默认为当前 namespacespec:progressDeadlineSeconds:600# 默认值replicas:3# --replicasselector:matchLabels:app:my-nginx-5template:metadata:labels:app:my-nginx-5spec:containers:- image:nginx:alpine # --imageimagePullPolicy:IfNotPresentname:nginx# 根据镜像名字获取ports:# --port- containerPort:80protocol:TCP# ... 省略 ...  在使用命令行传递参数的时候只传递了 name, image, replicas, pods\n  kubectl 根据传递的信息， 自动补全了一些信息\n 以 name 补全了 labels： app: my-nginx-5 以 image 生成了 container name； 如果传递多个 相同名称 image 将会报错 container name 冲突。    接下来的工作就真没什么技术含量了， 就是最简单最无脑的拼凑字段。\n在 Annotations 字段中， 也可以夹带很多 私货。 例如， 在 CI 中可以加入很多关于 commit 的信息， 例如 提交人， 提交信息 等。 一切想夹带的都可以放进去。\ntype CreateDeploymentInput struct { Name string Replicas *int32 Images []string } func CreateDeployment(ctx context.Context, namespace string, input CreateDeploymentInput) (*appsv1.Deployment, error) { labels := map[string]string{ \u0026#34;app\u0026#34;: input.Name, } dep := \u0026amp;appsv1.Deployment{ ObjectMeta: metav1.ObjectMeta{ Name: input.Name, Namespace: namespace, Labels: labels, // 在 CI 的时候， 可以在这里加上关键的 commit 信息。 \tAnnotations: map[string]string{ \u0026#34;manager\u0026#34;: \u0026#34;k8sailor\u0026#34;, }, }, Spec: appsv1.DeploymentSpec{ Replicas: input.Replicas, Selector: \u0026amp;metav1.LabelSelector{ MatchLabels: labels, }, Template: corev1.PodTemplateSpec{ ObjectMeta: metav1.ObjectMeta{ Labels: labels, }, Spec: corev1.PodSpec{ Containers: containers(input.Images), }, }, }, } opts := metav1.CreateOptions{} return clientset.AppsV1().Deployments(namespace).Create(ctx, dep, opts) } func containers(images []string) []corev1.Container { containers := make([]corev1.Container, len(images)) for i, image := range images { container := corev1.Container{ Image: image, Name: imageName(i, image), } containers[i] = container } return containers } 一个标准的 image 地址类似 docker.io/libray/nginx:1.13-alpine。 其中出现了多种特殊符号。 而 container name 只允许 小写字母， 数字，-， 所以需要改造一下。 为了解决相同镜像冲突的问题， 还在末尾加上了 container 的 id\n// image: docker.io/libray/nginx:1.13-alpine func imageName(i int, image string) string { for _, char := range []string{\u0026#34;/\u0026#34;, \u0026#34;:\u0026#34;, \u0026#34;.\u0026#34;} { image = strings.ReplaceAll(image, char, \u0026#34;-\u0026#34;) } return fmt.Sprintf(\u0026#34;%s-%d\u0026#34;, image, i) } 写下来也发现了一个问题 ， 即使要拼凑字段， 也不应该写在一个结构体中。\n 本身 k8s 提供的诸多 Workloads 就是对 Pods 的 调度管理 的一层抽象，从而应对不同的场景。 Pod 与 Containers 之间是一个组合关系。 Container 和 InitContainer 本身是一样的， 只是在不同阶段运行的区分。  因此， 更应该将三个 Spec 分开处理， 这样就能更好、更方便的进行组合复用。\n 向 Container 的构造函数中传入关键参数, 创建 Container 对象: NewContainerSpec(params) 向 Pod 的构造函数中传入 关键参数和 container 对象， 创建 Pod 对象: NewPodSpec(params, containers) 向 Deployment(或其他 Workload) 的构造函数中传入 关键参数和 pod 对象， 创建 Deployment 对象， NewDeploymentSpec(params, pod)  ","description":"创建 deployment      tag: https://github.com/tangx/k8sailor/tree/feat/16-create-deployment\n 使用 kubectl 命令创建如下\nkubectl create deployment my-nginx-5 --image=nginx:alpine --replicas=3 --port=80 创建成功后查看结果， 大部分参数为默认参数。\n# kgd -o yaml my-nginx-5apiVersion:apps/v1kind:Deploymentmetadata:labels:app:my-nginx-5# 根据 deployment 自动匹配名字自动生成name:my-nginx-5 # 用户指定namespace:default# 用户选择，默认为当前 namespacespec:progressDeadlineSeconds:600# 默认值replicas:3# --replicasselector:matchLabels:app:my-nginx-5template:metadata:labels:app:my-nginx-5spec:containers:- image:nginx:alpine # --imageimagePullPolicy:IfNotPresentname:nginx# 根据镜像名字获取ports:# --port- containerPort:80protocol:TCP# ... 省略 ...  在使用命令行传递参数的时候只传递了 name, image, replicas, pods\n  kubectl 根据传递的信息， 自动补全了一些信息\n 以 name 补全了 labels： app: my-nginx-5 以 image 生成了 container name； 如果传递多个 相同名称 image 将会报错 container name 冲突。    接下来的工作就真没什么技术含量了， 就是最简单最无脑的拼凑字段。"},{"id":17,"href":"/books/k8sailor/chapter02/17-pod-phase-and-status/","title":"17 Pod Phase and Status","parent":"Chapter02","content":"Pod 的阶段(phase)与状态(status)     Pod 的生命周期 https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/\n Pod 的 Status 不是 Phase。\nPod 的 Status 需要根据 Pod 中的 ContainerStatuses 进行计算得到。\nPhase        阶段 描述     Pending（悬决） Pod 已被 Kubernetes 系统接受，但有一个或者多个容器尚未创建亦未运行。此阶段包括等待 Pod 被调度的时间和通过网络下载镜像的时间，   Running（运行中） Pod 已经绑定到了某个节点，Pod 中所有的容器都已被创建。至少有一个容器仍在运行，或者正处于启动或重启状态。   Succeeded（成功） Pod 中的所有容器都已成功终止，并且不会再重启。   Failed（失败） Pod 中的所有容器都已终止，并且至少有一个容器是因为失败终止。也就是说，容器以非 0 状态退出或者被系统终止。   Unknown（未知） 因为某些原因无法取得 Pod 的状态。这种情况通常是因为与 Pod 所在主机通信失败。     其中 Running 阶段包含了很多行为， 如 1. 下载镜像，2. 启动并初始化，3. 对外提供服务， 而通常认为的 Pod 处于正常服务状态（1. 能接受请求或发送请求， 2. pod 不退出） 只能该阶段的一部分，算 3.对外提供服务。\n虽然 kubectl 工具使用 kubectl get pod 可以查看到 Status 这个状态。\n→ kgp NAME READY STATUS RESTARTS AGE my-nginx-6-5f55fd588f-pzn5m 1/1 Running 0 2d3h new-nginx-04-5f94fffcdc-2gkbd 1/1 Running 0 44h new-nginx-04-5f94fffcdc-wbnnw 1/1 Running 0 44h new-nginx-05-799c589bdc-84tf2 1/2 CrashLoopBackOff 527 44h new-nginx-03-69bd55dc6d-5c8d6 1/2 CrashLoopBackOff 472 40h 但 k8s api 中并没有直接给出 Pod 的实际状态， 虽然 Pod 的 Status 字段中有 Reason 和 Message 两个字段，但其内容一直为空，暂时没有发现有什么用处。\n// k8s.io/api@v0.21.4/core/v1/types.go type PodStatus struct { // A human readable message indicating details about why the pod is in this condition. \t// +optional \tMessage string `json:\u0026#34;message,omitempty\u0026#34; protobuf:\u0026#34;bytes,3,opt,name=message\u0026#34;` // A brief CamelCase message indicating details about why the pod is in this state. \t// e.g. \u0026#39;Evicted\u0026#39; \t// +optional \tReason string `json:\u0026#34;reason,omitempty\u0026#34; protobuf:\u0026#34;bytes,4,opt,name=reason\u0026#34;` } 因此， 如果要实现类似 kubectl 展示 Pod Status 的情况， 就需要自己去 PodConditions 中去 获取所有 Container 状态 并分析、计算、返回。 顺便提一句， 这里并不知道 kubectl 是怎么实现的， interface 太多，不知道怎么追踪。 真失败 T.T 。\n根据 Container 状态获取 Pod 状态     // extractPod 转换成业务本身的 Pod func extractPod(item corev1.Pod) *Pod { reason := \u0026#34;\u0026#34; message := \u0026#34;\u0026#34; // 计算 Pod 在 Phase Running 时候的真实 Status \tfor _, status := range item.Status.ContainerStatuses { if !status.Ready \u0026amp;\u0026amp; status.State.Waiting != nil { reason = status.State.Waiting.Reason message = status.State.Waiting.Message break } } return \u0026amp;Pod{ Name: item.Name, Namespace: item.Namespace, Images: PodImages(item.Spec), NodeName: item.Spec.NodeName, NodeIp: item.Status.HostIP, CreateTime: item.CreationTimestamp.Time, PodIP: item.Status.PodIP, Status: PodStatus{ Phase: item.Status.Phase, Message: message, Reason: reason, }, Labels: item.Labels, } } ","description":"Pod 的阶段(phase)与状态(status)     Pod 的生命周期 https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/\n Pod 的 Status 不是 Phase。\nPod 的 Status 需要根据 Pod 中的 ContainerStatuses 进行计算得到。\nPhase        阶段 描述     Pending（悬决） Pod 已被 Kubernetes 系统接受，但有一个或者多个容器尚未创建亦未运行。此阶段包括等待 Pod 被调度的时间和通过网络下载镜像的时间，   Running（运行中） Pod 已经绑定到了某个节点，Pod 中所有的容器都已被创建。至少有一个容器仍在运行，或者正处于启动或重启状态。   Succeeded（成功） Pod 中的所有容器都已成功终止，并且不会再重启。   Failed（失败） Pod 中的所有容器都已终止，并且至少有一个容器是因为失败终止。也就是说，容器以非 0 状态退出或者被系统终止。   Unknown（未知） 因为某些原因无法取得 Pod 的状态。这种情况通常是因为与 Pod 所在主机通信失败。     其中 Running 阶段包含了很多行为， 如 1."},{"id":18,"href":"/books/k8sailor/chapter02/18-vue3-create-deployment/","title":"18 Vue3 Create Deployment","parent":"Chapter02","content":"创建 deployment     ","description":"创建 deployment     "},{"id":19,"href":"/books/k8sailor/chapter02/19-create-service/","title":"19 Create Service","parent":"Chapter02","content":"为 Deployment 创建 Service      tag: https://github.com/tangx/k8sailor/tree/feat/19-create-service\n  https://kubernetes.io/zh/docs/concepts/services-networking/service/#externalname\n kubectl create service clusterip nginx-web --clusterip=\u0026#34;port:targetPort\u0026#34; kubectl create service clusterip nginx-web --clusterip=\u0026#34;8082:80\u0026#34; kubectl create service nodeport nginx-web --clusterip=\u0026#34;8081:80\u0026#34; 需要注意, 使用 kubectl get service 查看到的 Ports 的展示结果为 port:nodePort， 而 targetPort 不展示。\n# kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE demo-nginx-nodeport-3 NodePort 10.43.181.29 \u0026lt;none\u0026gt; 80:32425/TCP 4s port, targetPort, nodePort      端口映射中的四个 比较关键 的要素:\n name: 避免端口相同时，默认名字冲突 port: service 对外提供服务的端口 targetPort: service 指向的 pod 的端口， 即 pod 对外服务的端口。 nodePort: node 对外提供服务的端口， 通过 kube-proxy 修改 iptables 将流量转发到 service 上。  其中， targetPort 可以是 string / int32 的复合类型， 定义如下。\n// k8s.io/api@v0.21.4/core/v1/types.go  // ServicePort contains information on service\u0026#39;s port. type ServicePort struct { // Number or name of the port to access on the pods targeted by the service. \t// Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. \t// If this is a string, it will be looked up as a named port in the \t// target Pod\u0026#39;s container ports. If this is not specified, the value \t// of the \u0026#39;port\u0026#39; field is used (an identity map). \t// This field is ignored for services with clusterIP=None, and should be \t// omitted or set equal to the \u0026#39;port\u0026#39; field. \t// More info: https://kubernetes.io/docs/concepts/services-networking/service/#defining-a-service \t// +optional \tTargetPort intstr.IntOrString `json:\u0026#34;targetPort,omitempty\u0026#34; protobuf:\u0026#34;bytes,4,opt,name=targetPort\u0026#34;` } 在 apimachinery(k8s.io/apimachinery@v0.21.4/pkg/util/) 包中， 提供了很多针对 k8s 对象的常用方法。\n解析 port     为了能简化 api 请求的参数， 因此对 clusterIp 和 nodePort 使用了符号表示： 默认为 clusterIp， 如果有 叹号! 则为 nodePort。\nport // clusterIp, port 与 targetPort 一致 port:targetPort // clusterIp, port 与 targetPort 可能不一致  !port:targetPort // nodeport, 端口号随机: port 与 targetPort 可能不一致 !nodePort:port:targetPort // nodeport, 指定端口号, 端口可能因为被使用而创建失败 headless service     对 statefuleset 有效， 对 deployment 无效\n https://kubernetes.io/zh/docs/concepts/workloads/controllers/statefulset/\n  使用 headless 之后， k8s 将不再创建 service 进行 pod 的负载均衡。 取而代之的是 DNS 将每个 pod 直接解析暴露， 域名规则 podName.serviceName.namespace.Cluster。\n 注意: statefuleSet 对与绑定的 serviceName 是有强力约束的。 只有匹配名字的 service 才能提供响应的服务。\n apiVersion:apps/v1kind:StatefulSetmetadata:name:webspec:selector:matchLabels:app:nginx serviceName:\u0026#34;nginx\u0026#34;# 约束只能匹配名为 `nginx` 的 servicereplicas:3template:# .... 省略解析 Headless Port     kubectl create service clusterip my-nginx-web --clusterip=\u0026#34;None\u0026#34; --tcp=8088:80 从 kubectl 的命令中可以看到， Headless Service 可以被认为 clusterip 的一个子类， 其特殊之处就是 ClusterIp: None\n鉴于此， 对之前的 Port 规则进行了一定扩展。\n规则基本类似， 采用了的新的符号 # 表示 Headless 服务。 # 在很多地方表示注释， 注释对外看不见，因此用以表示 Headless。\n#port:targetPort // headless 本身 NodePort 和 Headless 就是不兼容的， 由于 #, ! 在同一个位置， 也一定程度上避免了 误写\nexternal name     externalName service 就是 k8s 集群通过 coredns 实现的 CNAME 服务， 从而实现了 在集群内部不依赖外部地址 的内聚效果。\n无论依赖资源地址是否发生变化（例如 迁移）， 客户端服务都不需要进行任何变更，只需要通过外部配置更新 service 的 externalName 即可完成切换。\n kubectl create service externalname my-ns --external-name www.baidu.com # kgs my-ns -o yamlapiVersion:v1kind:Servicemetadata:labels:app:my-nsname:my-nsnamespace:defaultspec:externalName:www.baidu.com# selector: # external 是不需要选择器的# app: my-nssessionAffinity:Nonetype:ExternalName通过 ping 命令可以看到， my-ns 和 www.baidu.com 结果是一样的。\n# ping my-ns PING www.a.shifen.com (110.242.68.4) 56(84) bytes of data. 64 bytes from 110.242.68.4 (110.242.68.4): icmp_seq=1 ttl=48 time=12.2 ms 64 bytes from 110.242.68.4 (110.242.68.4): icmp_seq=2 ttl=48 time=12.1 ms # ping www.baidu.com PING www.a.shifen.com (110.242.68.3) 56(84) bytes of data. 64 bytes from 110.242.68.3 (110.242.68.3): icmp_seq=1 ttl=48 time=11.2 ms 64 bytes from 110.242.68.3 (110.242.68.3): icmp_seq=2 ttl=48 time=11.2 ms 解析 externalName     由于 externalName 是完全的 DNS 行为。 1. 没有 pod 映射， 2. 也不需要 label selector 选择后端的提供服务的 Pod。 因此， 之前的 port:targetPort 规则也就用不上了。\n对于 externalName 引入了新的符号 at @ ， @ 本身也有 到、去 目的地的意思。\n@external.name 总结     # k create service --help Available Commands: clusterip Create a ClusterIP service. externalname Create an ExternalName service. loadbalancer 创建一个 LoadBalancer service. nodeport 创建一个 NodePort service. 自此 kubectl 创建 service 常用的几个子命令已经实现了。\n clusterip:  normal: port:targetPort headless: #port:targetPort   externalname: @external.com nodeport:  指定 nodePort 端口: !nodeport:port:targetPort 随机 nodePort 端口: !port:targetPort    demo     services 中的参数互斥， 不能共用。\n### CREATE servcie , Headless POST http://127.0.0.1:8088/k8sailor/v0/services/demo-nginx-211?namespace=default Content-Type: application/json { \u0026#34;services\u0026#34;:[ \u0026#34;80:8088\u0026#34;, # clusterip \u0026#34;#80:80\u0026#34;, # headless \u0026#34;!31234:80:8088\u0026#34;, # nodeport \u0026#34;@www.baidu.com\u0026#34;, # external name ] } ","description":"为 Deployment 创建 Service      tag: https://github.com/tangx/k8sailor/tree/feat/19-create-service\n  https://kubernetes.io/zh/docs/concepts/services-networking/service/#externalname\n kubectl create service clusterip nginx-web --clusterip=\u0026#34;port:targetPort\u0026#34; kubectl create service clusterip nginx-web --clusterip=\u0026#34;8082:80\u0026#34; kubectl create service nodeport nginx-web --clusterip=\u0026#34;8081:80\u0026#34; 需要注意, 使用 kubectl get service 查看到的 Ports 的展示结果为 port:nodePort， 而 targetPort 不展示。\n# kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE demo-nginx-nodeport-3 NodePort 10.43.181.29 \u0026lt;none\u0026gt; 80:32425/TCP 4s port, targetPort, nodePort      端口映射中的四个 比较关键 的要素:"},{"id":20,"href":"/books/k8sailor/chapter02/20-create-ingress/","title":"20 Create Ingress","parent":"Chapter02","content":"创建 ingress      tag: https://github.com/tangx/k8sailor/tree/feat/20-create-ingress\n k8s ingress      https://kubernetes.io/zh/docs/concepts/services-networking/ingress/\n # Create an ingress with a default backend kubectl create ingress ingdefault --class=default \\  --default-backend=defaultsvc:http \\  --rule=\u0026#34;foo.com/*=svc:8080,tls=secret1\u0026#34; --dry-run -o yaml apiVersion:networking.k8s.io/v1kind:Ingressmetadata:creationTimestamp:nullname:ingdefaultspec:defaultBackend:service:name:defaultsvcport:name:httpingressClassName:defaultrules:- host:foo.comhttp:paths:- backend:service:name:svcport:number:8080path:/pathType:Prefix # 匹配方式tls:- hosts:- foo.comsecretName:secret1status:loadBalancer:{}路径类型     Ingress 中的每个路径都需要有对应的路径类型（Path Type）。未明确设置 pathType 的路径无法通过合法性检查。当前支持的路径类型有三种：\nImplementationSpecific ：对于这种路径类型，匹配方法取决于 IngressClass。 具体实现可以将其作为单独的 pathType 处理或者与 Prefix 或 Exact 类型作相同处理。\nExact ：精确匹配 URL 路径，且区分大小写。\nPrefix ：基于以 / 分隔的 URL 路径前缀匹配。匹配区分大小写，并且对路径中的元素逐个完成。 路径元素指的是由 / 分隔符分隔的路径中的标签列表。 如果每个 p 都是请求路径 p 的元素前缀，则请求与路径 p 匹配。\n说明： 如果路径的最后一个元素是请求路径中最后一个元素的子字符串，则不会匹配 （例如：/foo/bar 匹配 /foo/bar/baz, 但不匹配 /foo/barbaz）。\n 不建议使用 ImplementationSpecific，因为这个参数实现的功能取决于 IngressClass / IngressController ， 对用户 1. 或不可控， 2. 或认知盲点。 如果后期换了一个 Controller 或换了一个人维护则可能出现异常。\n 事实上， 在 kubectl create ingress 的时候， 也是通过判断 rule 中的 uri 最后一个字符是否为 * 号确定使用使用哪种规则。 有 * 使用 prefix， 没有使用 exact 。\nAPI 请求体设计     endpoint 传递方式     因此我们采用 k8s 的规则， 使用 * 座位 PathType 的描述符。\n### Post ingress POST http://127.0.0.1:8088/k8sailor/v0/ingresses/my-nginx-5?namespace=default Content-Type: application/json { \u0026quot;endpoints\u0026quot;:[ \u0026quot;http://www.baidu.com/v0\u0026quot;, \u0026quot;http://www.baidu.com/v1/api/*?backend=svc-google:443\u0026amp;tls=google-tls\u0026quot; ] } 在 ingress 参数设计的时候， 考虑到 URL 的可读性，\n 直接将多个字段合并成了一个整体， 可以通过转换成 url.URL 进行解构，获取其中的关键字段。 在规则参数的传递上，为了更符合一个 RFC 3986 URI 规定, 所以使用 query 进行参数传递。  http://www.example.com:20080/v1/api/*?backend=svc-google:443\u0026amp;tls=google-tls  host 不支持 IP 地址， 也就是说 http://192.168.100.100/v1/api 是不合法的。 在 IngressRule 规则中， 不支持 显式 指定端口， 目前是通过 http / https 协议 隐式 实现的的 80 / 443 端口。 host 可以为 空 将转发所有请求。 host 为域名时只转发匹配域名的请求。   https://pkg.go.dev/k8s.io/api@v0.21.4/networking/v1#IngressRule\n 这里的 port 其实并没有用， 保留设计只是为了 标识 外部入口使用的端口。 这种情况在云上遇到的不多， 但在一些实施项目上由于可能会遇到，例如域名没有备案。\n backend service 默认值     除此之外， 在实现的时候 query 参数 backend=svc-google:port 进行了一些默认值处理\n  如果不传递 backend， 将默认使用 ingressName 作为 serviceName。 这个主要是为了服务名称的统一性。 ingress -\u0026gt; service -\u0026gt; workloads 使用相同名字， 更具有识别性。\n  port 如果不传递， 默认是 80\n   注意: 在创建 service 的时候， port 是可以具名的， 这个 port 名字 也是能被使用的。 因此 portName 最好不要使用 纯数字， 避免造成混淆。\n 以下是对 ServiceBackendPort 的定义， 支持 string 的 name 和 int32 的 Number\n// k8s.io/api@v0.21.4/networking/v1/types.go // ServiceBackendPort is the service port being referenced. type ServiceBackendPort struct { // Name is the name of the port on the Service. \t// This is a mutually exclusive setting with \u0026#34;Number\u0026#34;. \t// +optional \tName string `json:\u0026#34;name,omitempty\u0026#34; protobuf:\u0026#34;bytes,1,opt,name=name\u0026#34;` // Number is the numerical port number (e.g. 80) on the Service. \t// This is a mutually exclusive setting with \u0026#34;Name\u0026#34;. \t// +optional \tNumber int32 `json:\u0026#34;number,omitempty\u0026#34; protobuf:\u0026#34;bytes,2,opt,name=number\u0026#34;` } ","description":"创建 ingress      tag: https://github.com/tangx/k8sailor/tree/feat/20-create-ingress\n k8s ingress      https://kubernetes.io/zh/docs/concepts/services-networking/ingress/\n # Create an ingress with a default backend kubectl create ingress ingdefault --class=default \\  --default-backend=defaultsvc:http \\  --rule=\u0026#34;foo.com/*=svc:8080,tls=secret1\u0026#34; --dry-run -o yaml apiVersion:networking.k8s.io/v1kind:Ingressmetadata:creationTimestamp:nullname:ingdefaultspec:defaultBackend:service:name:defaultsvcport:name:httpingressClassName:defaultrules:- host:foo.comhttp:paths:- backend:service:name:svcport:number:8080path:/pathType:Prefix # 匹配方式tls:- hosts:- foo.comsecretName:secret1status:loadBalancer:{}路径类型     Ingress 中的每个路径都需要有对应的路径类型（Path Type）。未明确设置 pathType 的路径无法通过合法性检查。当前支持的路径类型有三种：\nImplementationSpecific ：对于这种路径类型，匹配方法取决于 IngressClass。 具体实现可以将其作为单独的 pathType 处理或者与 Prefix 或 Exact 类型作相同处理。\nExact ：精确匹配 URL 路径，且区分大小写。"},{"id":21,"href":"/books/k8sailor/chapter01/","title":"Chapter01","parent":"","content":"","description":""},{"id":22,"href":"/books/k8sailor/chapter02/","title":"Chapter02","parent":"","content":"","description":""},{"id":23,"href":"/books/k8sailor/tags/","title":"Tags","parent":"","content":"","description":""}]